{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d67f9d24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d67f9d24",
        "outputId": "8ef70f66-4e21-4889-f7c3-b563a7ee7640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ Starting Ultra-Minimized Urdu Chatbot with Enhanced Context Representation\n",
            "ðŸ“ This notebook should be run sequentially from top to bottom\n",
            "âœ… Cell 1: Ready to proceed!\n"
          ]
        }
      ],
      "source": [
        "# ðŸŽ¯ NOTEBOOK EXECUTION ORDER VERIFICATION\n",
        "print(\"ðŸŽ¯ Starting Ultra-Minimized Urdu Chatbot with Enhanced Context Representation\")\n",
        "print(\"ðŸ“ This notebook should be run sequentially from top to bottom\")\n",
        "print(\"âœ… Cell 1: Ready to proceed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abdf8c43",
      "metadata": {
        "id": "abdf8c43"
      },
      "source": [
        "# ðŸ¤– Ultra-Minimized Urdu Conversational Chatbot\n",
        "\n",
        "## ðŸ“š Assignment Requirements Implementation:\n",
        "\n",
        "### 1. Data Preprocessing âœ…\n",
        "- âœ… **ENHANCED Normalize Urdu text**:\n",
        "  - ðŸ”§ Remove ALL diacritics (20+ marks: Ù‹ ÙŒ Ù ÙŽ Ù Ù Ù‘ Ù’ Ù° + more)\n",
        "  - ðŸ”§ Standardize ALL Alef forms (Ø¢ Ø£ Ø¥ Ù± â†’ Ø§)\n",
        "  - ðŸ”§ Standardize ALL Yeh forms (Û’ ÙŠ Ù‰ Ø¦ â†’ ÛŒ)\n",
        "  - ðŸ”§ Teh Marbuta normalization (Ø© â†’ Øª)\n",
        "  - ðŸ”§ Arabic-Urdu number conversion (Ù -Ù© â†’ Û°-Û¹)\n",
        "- âœ… **Tokenize sentences**: SentencePiece tokenizer with 8K vocabulary\n",
        "- âœ… **Dataset split**: Train 80%, Validation 10%, Test 10%\n",
        "\n",
        "### 2. Model Architecture âœ…  \n",
        "- âœ… **Transformer Encoder-Decoder**: Built from scratch using PyTorch\n",
        "- âœ… **Multi-Head Attention**: 2 heads with Query, Key, Value projections\n",
        "- âœ… **Positional Encoding**: Sinusoidal encoding for sequence positions\n",
        "- âœ… **Feed-Forward Networks**: Position-wise FFN with ReLU activation\n",
        "- âœ… **Encoder**: Captures context from full input sequence\n",
        "- âœ… **Decoder**: Generates responses token-by-token with teacher forcing\n",
        "\n",
        "### 3. Technical Specifications âœ…\n",
        "- âœ… Embedding dimensions: 256\n",
        "- âœ… Encoder/Decoder layers: 2 each\n",
        "- âœ… Batch size: 32, Learning rate: 1e-4\n",
        "- âœ… Cross-entropy loss on predicted vs masked tokens\n",
        "- âœ… All components saved in pickle format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "eb54e52b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb54e52b",
        "outputId": "f23c5b5b-e1d9-4463-f686-ed08db584696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¦ Installing all required packages for enhanced chatbot...\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2.0.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (5.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.10.5)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3/3\u001b[0m [sacrebleu]\n",
            "\u001b[1A\u001b[2KSuccessfully installed colorama-0.4.6 portalocker-3.2.0 sacrebleu-2.5.1\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "âœ… All packages installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# ðŸ“¦ INSTALL ALL REQUIRED PACKAGES\n",
        "print(\"ðŸ“¦ Installing all required packages for enhanced chatbot...\")\n",
        "!pip install --upgrade pip\n",
        "!pip install kagglehub sentencepiece sacrebleu torch torchvision tqdm\n",
        "!pip install scikit-learn pandas numpy matplotlib seaborn\n",
        "print(\"âœ… All packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "18fb1d24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18fb1d24",
        "outputId": "19fabce4-6541-405f-82fa-20b19c0502b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“š Importing all required libraries...\n",
            "ðŸ–¥ï¸ Device: cuda\n",
            "ðŸ“ Files will be saved to: /content/urdu_files/\n",
            "âœ… All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# ðŸ“š IMPORT ALL LIBRARIES (Complete Import Section)\n",
        "print(\"ðŸ“š Importing all required libraries...\")\n",
        "\n",
        "# Basic libraries\n",
        "import os, random, math, json, pickle, shutil\n",
        "import numpy as np, pandas as pd, sentencepiece as spm\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# PyTorch libraries\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# NLP and evaluation libraries\n",
        "import sacrebleu, kagglehub\n",
        "\n",
        "# Enhanced features libraries\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from collections import defaultdict\n",
        "import itertools\n",
        "\n",
        "# Setup random seeds for reproducibility\n",
        "torch.manual_seed(42), np.random.seed(42), random.seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs('/content/urdu_files', exist_ok=True)\n",
        "\n",
        "print(f\"ðŸ–¥ï¸ Device: {device}\")\n",
        "print(f\"ðŸ“ Files will be saved to: /content/urdu_files/\")\n",
        "print(f\"âœ… All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "feb6b698",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feb6b698",
        "outputId": "1f5953ef-8814-4ae4-b4c1-9c0a7e1820af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Downloading dataset and extracting Urdu sentences from column 3...\n",
            "Using Colab cache for faster access to the 'urdu-dataset-20000' dataset.\n",
            "âœ… Dataset downloaded successfully!\n",
            "ðŸ“ Dataset path: /kaggle/input/urdu-dataset-20000\n",
            "ðŸ“„ Available files: ['final_main_dataset.tsv', 'model_checkpoint_v2.h5', 'char_to_num_vocab.pkl', 'limited_wav_files']\n",
            "ðŸŽ¯ Found target file: final_main_dataset.tsv\n",
            "âœ… Successfully loaded: final_main_dataset.tsv\n",
            "ðŸ“‹ Original columns: ['client_id', 'path', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant', 'locale', 'segment']\n",
            "ðŸ“Š Dataset shape: (20000, 11)\n",
            "âœ… Extracted column 3: sentence\n",
            "ðŸ”§ Applying enhanced Urdu text normalization...\n",
            "ðŸ“Š After enhanced cleaning: 20000 valid Urdu sentences\n",
            "\n",
            "ðŸ“ Normalization Examples:\n",
            "   1. No change: Ú©Ø¨Ú¾ÛŒ Ú©Ø¨Ú¾Ø§Ø± ÛÛŒ Ø®ÛŒØ§Ù„ÛŒ Ù¾Ù„Ø§Ùˆ Ø¨Ù†Ø§ØªØ§ ÛÙˆÚº...\n",
            "   2. Before: Ø§ÙˆØ± Ù¾Ú¾Ø± Ù…Ù…Ú©Ù† ÛÛ’ Ú©Û Ù¾Ø§Ú©Ø³ØªØ§Ù† Ø¨Ú¾ÛŒ ÛÙˆ...\n",
            "      After:  Ø§ÙˆØ± Ù¾Ú¾Ø± Ù…Ù…Ú©Ù† ÛÛŒ Ú©Û Ù¾Ø§Ú©Ø³ØªØ§Ù† Ø¨Ú¾ÛŒ ÛÙˆ...\n",
            "   3. No change: ÛŒÛ ÙÛŒØµÙ„Û Ø¨Ú¾ÛŒ Ú¯Ø²Ø´ØªÛ Ø¯Ùˆ Ø³Ø§Ù„ Ù…ÛŒÚº...\n",
            "\n",
            "âœ… Enhanced Urdu sentences saved as dataset.csv\n",
            "ðŸ“Š Final dataset: 20000 normalized Urdu sentences\n",
            "ðŸ“ Sample normalized sentences:\n",
            "   1. Ú©Ø¨Ú¾ÛŒ Ú©Ø¨Ú¾Ø§Ø± ÛÛŒ Ø®ÛŒØ§Ù„ÛŒ Ù¾Ù„Ø§Ùˆ Ø¨Ù†Ø§ØªØ§ ÛÙˆÚº...\n",
            "   2. Ø§ÙˆØ± Ù¾Ú¾Ø± Ù…Ù…Ú©Ù† ÛÛŒ Ú©Û Ù¾Ø§Ú©Ø³ØªØ§Ù† Ø¨Ú¾ÛŒ ÛÙˆ...\n",
            "   3. ÛŒÛ ÙÛŒØµÙ„Û Ø¨Ú¾ÛŒ Ú¯Ø²Ø´ØªÛ Ø¯Ùˆ Ø³Ø§Ù„ Ù…ÛŒÚº...\n",
            "\n",
            "ðŸ’¾ Files saved to: /content/urdu_files/dataset.csv\n",
            "ðŸ”§ Enhanced normalization includes:\n",
            "   âœ… Comprehensive diacritics removal (20+ marks)\n",
            "   âœ… All Alef forms â†’ Ø§ (Ø¢ Ø£ Ø¥ Ù±)\n",
            "   âœ… All Yeh forms â†’ ÛŒ (Û’ ÙŠ Ù‰ Ø¦)\n",
            "   âœ… Teh Marbuta â†’ Øª (Ø©)\n",
            "   âœ… Arabic numbers â†’ Urdu numbers\n",
            "   âœ… Normalized spaces and punctuation\n"
          ]
        }
      ],
      "source": [
        "# ðŸ“¥ EXTRACT URDU SENTENCES FROM final_main_dataset.tsv\n",
        "print(\"ðŸ“¥ Downloading dataset and extracting Urdu sentences from column 3...\")\n",
        "\n",
        "# Download the complete dataset first\n",
        "dataset_path = kagglehub.dataset_download(\"muhammadahmedansari/urdu-dataset-20000\")\n",
        "print(f\"âœ… Dataset downloaded successfully!\")\n",
        "\n",
        "# Check available files in the dataset\n",
        "print(f\"ðŸ“ Dataset path: {dataset_path}\")\n",
        "available_files = os.listdir(dataset_path)\n",
        "print(f\"ðŸ“„ Available files: {available_files}\")\n",
        "\n",
        "# Look specifically for final_main_dataset.tsv\n",
        "target_file = \"final_main_dataset.tsv\"\n",
        "df = None\n",
        "\n",
        "if target_file in available_files:\n",
        "    print(f\"ðŸŽ¯ Found target file: {target_file}\")\n",
        "    try:\n",
        "        filepath = os.path.join(dataset_path, target_file)\n",
        "        df = pd.read_csv(filepath, sep='\\t')\n",
        "        print(f\"âœ… Successfully loaded: {target_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed to read {target_file}: {str(e)}\")\n",
        "        df = None\n",
        "\n",
        "# If final_main_dataset.tsv not found, try other files as fallback\n",
        "if df is None:\n",
        "    print(\"ðŸ” final_main_dataset.tsv not found, trying other TSV files...\")\n",
        "    for filename in available_files:\n",
        "        if filename.endswith('.tsv'):\n",
        "            filepath = os.path.join(dataset_path, filename)\n",
        "            try:\n",
        "                print(f\"ðŸ” Trying to read: {filename}\")\n",
        "                df = pd.read_csv(filepath, sep='\\t')\n",
        "                print(f\"âœ… Successfully loaded: {filename}\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Failed to read {filename}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "if df is None:\n",
        "    raise FileNotFoundError(f\"No readable TSV file found in {available_files}\")\n",
        "\n",
        "print(f\"ðŸ“‹ Original columns: {df.columns.tolist()}\")\n",
        "print(f\"ðŸ“Š Dataset shape: {df.shape}\")\n",
        "\n",
        "# Extract 3rd column (index 2) containing Urdu sentences\n",
        "if len(df.columns) >= 3:\n",
        "    urdu_sentences = df.iloc[:, 2]  # 3rd column (0-indexed = 2)\n",
        "    print(f\"âœ… Extracted column 3: {df.columns[2]}\")\n",
        "\n",
        "    # ðŸ”§ ENHANCED URDU TEXT NORMALIZATION FUNCTION\n",
        "    def normalize_urdu_text(text):\n",
        "        \"\"\"\n",
        "        Comprehensive Urdu text normalization\n",
        "        - Remove all diacritics (Harakat, Tanween, etc.)\n",
        "        - Standardize Alef forms (Ø¢ Ø£ Ø¥ â†’ Ø§)\n",
        "        - Standardize Yeh forms (Û’ ÙŠ Ù‰ â†’ ÛŒ)\n",
        "        - Standardize Teh forms (Ø© â†’ Øª)\n",
        "        - Normalize spaces and punctuation\n",
        "        \"\"\"\n",
        "        if pd.isna(text): return \"\"\n",
        "        text = str(text).strip()\n",
        "\n",
        "        # 1. COMPREHENSIVE DIACRITICS REMOVAL\n",
        "        # All Arabic/Urdu diacritics and combining marks\n",
        "        diacritics = [\n",
        "            # Short vowels (Harakat)\n",
        "            'ÙŽ',  # Fatha\n",
        "            'Ù',  # Damma\n",
        "            'Ù',  # Kasra\n",
        "            'Ù’',  # Sukun\n",
        "\n",
        "            # Tanween (Nunation)\n",
        "            'Ù‹',  # Fathatan\n",
        "            'ÙŒ',  # Dammatan\n",
        "            'Ù',  # Kasratan\n",
        "\n",
        "            # Other diacritics\n",
        "            'Ù‘',  # Shadda (gemination)\n",
        "            'Ù°',  # Alef Superscript\n",
        "            'Ù–',  # Small High Seen\n",
        "            'Ù—',  # Small High Rounded Zero\n",
        "            'Ù˜ ',  # Small High Meem Isolated Form\n",
        "            'Ù‹',  # Small High Noon\n",
        "            'Û­',  # Small High Waw\n",
        "            'Û¨',  # Small High Noon\n",
        "\n",
        "            # Additional combining marks\n",
        "            '\\u064B', '\\u064C', '\\u064D', '\\u064E', '\\u064F',\n",
        "            '\\u0650', '\\u0651', '\\u0652', '\\u0653', '\\u0654',\n",
        "            '\\u0655', '\\u0656', '\\u0657', '\\u0658', '\\u0659',\n",
        "            '\\u065A', '\\u065B', '\\u065C', '\\u065D', '\\u065E',\n",
        "            '\\u065F', '\\u0670'\n",
        "        ]\n",
        "\n",
        "        for diac in diacritics:\n",
        "            text = text.replace(diac, '')\n",
        "\n",
        "        # 2. STANDARDIZE ALEF FORMS\n",
        "        # All Alef variants â†’ Standard Alef (Ø§)\n",
        "        alef_forms = {\n",
        "            'Ø¢': 'Ø§',  # Alef with Madda Above\n",
        "            'Ø£': 'Ø§',  # Alef with Hamza Above\n",
        "            'Ø¥': 'Ø§',  # Alef with Hamza Below\n",
        "            'Ù±': 'Ø§',  # Alef Wasla\n",
        "            'ïº': 'Ø§',  # Alef isolated form\n",
        "            'ïºŽ': 'Ø§',  # Alef final form\n",
        "        }\n",
        "\n",
        "        for variant, standard in alef_forms.items():\n",
        "            text = text.replace(variant, standard)\n",
        "\n",
        "        # 3. STANDARDIZE YEH FORMS\n",
        "        # All Yeh variants â†’ Standard Urdu Yeh (ÛŒ)\n",
        "        yeh_forms = {\n",
        "            'Û’': 'ÛŒ',  # Yeh Barree â†’ Yeh\n",
        "            'ÙŠ': 'ÛŒ',  # Arabic Yeh â†’ Urdu Yeh\n",
        "            'Ù‰': 'ÛŒ',  # Alef Maksura â†’ Yeh\n",
        "            'Ø¦': 'ÛŒ',  # Yeh with Hamza â†’ Yeh (simplified)\n",
        "            'ï¯¼': 'ÛŒ',  # Yeh Barree isolated\n",
        "            'ï¯½': 'ÛŒ',  # Yeh Barree final\n",
        "            'ï»¯': 'ÛŒ',  # Alef Maksura isolated\n",
        "            'ï»°': 'ÛŒ',  # Alef Maksura final\n",
        "        }\n",
        "\n",
        "        for variant, standard in yeh_forms.items():\n",
        "            text = text.replace(variant, standard)\n",
        "\n",
        "        # 4. STANDARDIZE TEH MARBUTA\n",
        "        # Teh Marbuta â†’ Teh\n",
        "        text = text.replace('Ø©', 'Øª')  # Teh Marbuta â†’ Teh\n",
        "\n",
        "        # 5. STANDARDIZE NUMBERS (Arabic to Urdu)\n",
        "        arabic_to_urdu_numbers = {\n",
        "            'Ù ': 'Û°', 'Ù¡': 'Û±', 'Ù¢': 'Û²', 'Ù£': 'Û³', 'Ù¤': 'Û´',\n",
        "            'Ù¥': 'Ûµ', 'Ù¦': 'Û¶', 'Ù§': 'Û·', 'Ù¨': 'Û¸', 'Ù©': 'Û¹'\n",
        "        }\n",
        "\n",
        "        for arabic_num, urdu_num in arabic_to_urdu_numbers.items():\n",
        "            text = text.replace(arabic_num, urdu_num)\n",
        "\n",
        "        # 6. NORMALIZE SPACES AND PUNCTUATION\n",
        "        # Remove extra spaces and normalize whitespace\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        # Standardize common punctuation\n",
        "        text = text.replace('Û”', 'Û”')  # Ensure correct Urdu full stop\n",
        "        text = text.replace('ØŸ', 'ØŸ')  # Ensure correct Urdu question mark\n",
        "        text = text.replace('ØŒ', 'ØŒ')  # Ensure correct Urdu comma\n",
        "\n",
        "        # Remove leading/trailing punctuation if isolated\n",
        "        text = text.strip('.,;:!?()[]{}\"\\'-')\n",
        "\n",
        "        return text.strip()\n",
        "\n",
        "    # Apply enhanced normalization and filter out empty sentences\n",
        "    print(\"ðŸ”§ Applying enhanced Urdu text normalization...\")\n",
        "    urdu_sentences = urdu_sentences.apply(normalize_urdu_text)\n",
        "    urdu_sentences = urdu_sentences[urdu_sentences.str.len() > 0]\n",
        "\n",
        "    print(f\"ðŸ“Š After enhanced cleaning: {len(urdu_sentences)} valid Urdu sentences\")\n",
        "\n",
        "    # Show normalization examples\n",
        "    print(f\"\\nðŸ“ Normalization Examples:\")\n",
        "    sample_before = df.iloc[:3, 2].tolist() if len(df) >= 3 else []\n",
        "    sample_after = urdu_sentences.head(3).tolist()\n",
        "\n",
        "    for i, (before, after) in enumerate(zip(sample_before, sample_after)):\n",
        "        if str(before) != str(after):\n",
        "            print(f\"   {i+1}. Before: {str(before)[:60]}...\")\n",
        "            print(f\"      After:  {str(after)[:60]}...\")\n",
        "        else:\n",
        "            print(f\"   {i+1}. No change: {str(after)[:60]}...\")\n",
        "\n",
        "    # Create simple dataset with only Urdu sentences\n",
        "    dataset_df = pd.DataFrame({\n",
        "        'sentence': urdu_sentences.tolist()\n",
        "    })\n",
        "\n",
        "    # Save as dataset.csv (simplified format)\n",
        "    os.makedirs('/content/urdu_files', exist_ok=True)\n",
        "    dataset_df.to_csv('/content/urdu_files/dataset.csv', index=False)\n",
        "\n",
        "    # Also save as pickle for faster loading\n",
        "    with open('/content/urdu_files/dataset.pkl', 'wb') as f:\n",
        "        pickle.dump(dataset_df, f)\n",
        "\n",
        "    print(f\"\\nâœ… Enhanced Urdu sentences saved as dataset.csv\")\n",
        "    print(f\"ðŸ“Š Final dataset: {len(dataset_df)} normalized Urdu sentences\")\n",
        "    print(f\"ðŸ“ Sample normalized sentences:\")\n",
        "    for i, sentence in enumerate(dataset_df['sentence'].head(3)):\n",
        "        print(f\"   {i+1}. {sentence[:100]}...\")\n",
        "\n",
        "else:\n",
        "    raise ValueError(f\"Dataset doesn't have enough columns! Found: {len(df.columns)} columns\")\n",
        "\n",
        "print(f\"\\nðŸ’¾ Files saved to: /content/urdu_files/dataset.csv\")\n",
        "print(f\"ðŸ”§ Enhanced normalization includes:\")\n",
        "print(f\"   âœ… Comprehensive diacritics removal (20+ marks)\")\n",
        "print(f\"   âœ… All Alef forms â†’ Ø§ (Ø¢ Ø£ Ø¥ Ù±)\")\n",
        "print(f\"   âœ… All Yeh forms â†’ ÛŒ (Û’ ÙŠ Ù‰ Ø¦)\")\n",
        "print(f\"   âœ… Teh Marbuta â†’ Øª (Ø©)\")\n",
        "print(f\"   âœ… Arabic numbers â†’ Urdu numbers\")\n",
        "print(f\"   âœ… Normalized spaces and punctuation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3f1d13d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f1d13d6",
        "outputId": "517a4632-5ae4-4be7-9769-5593d6f5b71c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Creating masked data and dataset class...\n",
            "âœ… Data: 3901 masked + 16000 original = 19901 total\n",
            "ðŸ“Š Split: Train 15920 | Val 1990 | Test 1991\n"
          ]
        }
      ],
      "source": [
        "# ðŸ“Š CREATE EFFICIENT MASKED DATA + DATASET CLASS\n",
        "print(\"ðŸ“Š Creating masked data and dataset class...\")\n",
        "\n",
        "urdu_sentences = dataset_df['sentence'].tolist()\n",
        "masked_size = int(len(urdu_sentences) * 0.2)\n",
        "\n",
        "# Create masked data (20%) with enhanced strategy\n",
        "masked_data = []\n",
        "for i in range(masked_size):\n",
        "    sentence = urdu_sentences[i]\n",
        "    words = sentence.split()\n",
        "    if len(words) > 2:\n",
        "        mask_count = max(1, int(len(words) * random.uniform(0.15, 0.25)))\n",
        "        mask_indices = random.sample(range(len(words)), min(mask_count, len(words)))\n",
        "        masked_words = words.copy()\n",
        "\n",
        "        for idx in mask_indices:\n",
        "            rand_val = random.random()\n",
        "            if rand_val < 0.8:\n",
        "                masked_words[idx] = \"[MASK]\"\n",
        "            elif rand_val < 0.9:\n",
        "                masked_words[idx] = random.choice(words)\n",
        "\n",
        "        masked_data.append({\n",
        "            'input': ' '.join(masked_words),\n",
        "            'target': sentence,\n",
        "            'mask_count': len(mask_indices)\n",
        "        })\n",
        "\n",
        "# Create original data (80%)\n",
        "original_data = [{'input': s, 'target': s, 'mask_count': 0}\n",
        "                for s in urdu_sentences[masked_size:]]\n",
        "\n",
        "all_training_data = masked_data + original_data\n",
        "random.shuffle(all_training_data)\n",
        "\n",
        "print(f\"âœ… Data: {len(masked_data)} masked + {len(original_data)} original = {len(all_training_data)} total\")\n",
        "\n",
        "# Enhanced Dataset Class\n",
        "class UrduDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len=128):\n",
        "        self.data, self.tokenizer, self.max_len = data, tokenizer, max_len\n",
        "\n",
        "    def __len__(self): return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        src_ids = self.tokenizer.encode(item['input'], add_bos=True, add_eos=True)[:self.max_len]\n",
        "        tgt_ids = self.tokenizer.encode(item['target'], add_bos=True, add_eos=True)[:self.max_len]\n",
        "\n",
        "        # Create loss mask for masked positions\n",
        "        loss_mask = torch.zeros(len(tgt_ids), dtype=torch.bool)\n",
        "        if item['mask_count'] > 0:\n",
        "            # Find masked positions by comparing input/target tokens\n",
        "            input_tokens = self.tokenizer.encode(item['input'], add_bos=False, add_eos=False)\n",
        "            target_tokens = self.tokenizer.encode(item['target'], add_bos=False, add_eos=False)\n",
        "            for i in range(min(len(input_tokens), len(target_tokens))):\n",
        "                if i < len(tgt_ids) - 1 and input_tokens[i] != target_tokens[i]:\n",
        "                    loss_mask[i + 1] = True\n",
        "        else:\n",
        "            loss_mask[1:] = True  # Language modeling\n",
        "\n",
        "        return {\n",
        "            'src_ids': torch.tensor(src_ids, dtype=torch.long),\n",
        "            'tgt_ids': torch.tensor(tgt_ids, dtype=torch.long),\n",
        "            'loss_mask': loss_mask,\n",
        "            'is_masked': item['mask_count'] > 0\n",
        "        }\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_ids = [item['src_ids'] for item in batch]\n",
        "    tgt_ids = [item['tgt_ids'] for item in batch]\n",
        "    loss_masks = [item['loss_mask'] for item in batch]\n",
        "    is_masked = [item['is_masked'] for item in batch]\n",
        "\n",
        "    max_len = max(max(len(s) for s in src_ids), max(len(t) for t in tgt_ids))\n",
        "\n",
        "    src_batch = torch.zeros(len(batch), max_len, dtype=torch.long)\n",
        "    tgt_batch = torch.zeros(len(batch), max_len, dtype=torch.long)\n",
        "    loss_mask_batch = torch.zeros(len(batch), max_len, dtype=torch.bool)\n",
        "\n",
        "    for i, (src, tgt, mask) in enumerate(zip(src_ids, tgt_ids, loss_masks)):\n",
        "        src_batch[i, :len(src)] = src\n",
        "        tgt_batch[i, :len(tgt)] = tgt\n",
        "        loss_mask_batch[i, :len(mask)] = mask\n",
        "\n",
        "    return {\n",
        "        'src': src_batch, 'tgt': tgt_batch, 'loss_mask': loss_mask_batch,\n",
        "        'is_masked': torch.tensor(is_masked, dtype=torch.bool)\n",
        "    }\n",
        "\n",
        "# Create splits\n",
        "total_size = len(all_training_data)\n",
        "train_size, val_size = int(total_size * 0.8), int(total_size * 0.1)\n",
        "train_data = all_training_data[:train_size]\n",
        "val_data = all_training_data[train_size:train_size + val_size]\n",
        "test_data = all_training_data[train_size + val_size:]\n",
        "\n",
        "print(f\"ðŸ“Š Split: Train {len(train_data)} | Val {len(val_data)} | Test {len(test_data)}\")\n",
        "\n",
        "# Save data\n",
        "for name, data in [('masked_data', masked_data), ('original_data', original_data),\n",
        "                   ('all_training_data', all_training_data)]:\n",
        "    with open(f'/content/urdu_files/{name}.pkl', 'wb') as f:\n",
        "        pickle.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fd2d6a41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd2d6a41",
        "outputId": "87cfe26e-6148-4fa9-8395-5bb21db46da4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¤ Training SentencePiece tokenizer on Urdu sentences...\n",
            "ðŸ“ Training tokenizer on 59802 Urdu texts\n",
            "ðŸ’¾ Saving tokenizer to Colab...\n",
            "âœ… Tokenizer trained: vocab size 8000\n",
            "ðŸ”¤ Training data: 59802 Urdu texts\n",
            "âœ… Tokenizer saved to /content/urdu_files/\n",
            "âœ… Vocabulary mapping saved: 8000 tokens\n"
          ]
        }
      ],
      "source": [
        "# ðŸ”¤ TRAIN SENTENCEPIECE TOKENIZER ON URDU DATASET\n",
        "print(\"ðŸ”¤ Training SentencePiece tokenizer on Urdu sentences...\")\n",
        "\n",
        "# Prepare training text from all Urdu data\n",
        "all_texts = []\n",
        "all_texts.extend(urdu_sentences)  # Original Urdu sentences\n",
        "\n",
        "# Add training data texts (input and target)\n",
        "for item in all_training_data:\n",
        "    all_texts.append(item['input'])\n",
        "    all_texts.append(item['target'])\n",
        "\n",
        "# Create training file for tokenizer\n",
        "with open('/tmp/urdu_training.txt', 'w', encoding='utf-8') as f:\n",
        "    for text in all_texts:\n",
        "        f.write(text + '\\n')\n",
        "\n",
        "print(f\"ðŸ“ Training tokenizer on {len(all_texts)} Urdu texts\")\n",
        "\n",
        "# Train SentencePiece model\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input='/tmp/urdu_training.txt',\n",
        "    model_prefix='/tmp/urdu_tokenizer',\n",
        "    vocab_size=8000,\n",
        "    model_type='bpe',\n",
        "    character_coverage=1.0,\n",
        "    pad_id=0, bos_id=1, eos_id=2, unk_id=3,\n",
        "    user_defined_symbols=['[MASK]']\n",
        ")\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = spm.SentencePieceProcessor()\n",
        "tokenizer.load('/tmp/urdu_tokenizer.model')\n",
        "\n",
        "VOCAB_SIZE, PAD_ID, BOS_ID, EOS_ID, UNK_ID = tokenizer.vocab_size(), 0, 1, 2, 3\n",
        "\n",
        "# ðŸ’¾ SAVE TOKENIZER TO COLAB\n",
        "print(\"ðŸ’¾ Saving tokenizer to Colab...\")\n",
        "\n",
        "# Copy tokenizer files\n",
        "shutil.copy('/tmp/urdu_tokenizer.model', '/content/urdu_files/tokenizer.model')\n",
        "shutil.copy('/tmp/urdu_tokenizer.vocab', '/content/urdu_files/tokenizer.vocab')\n",
        "\n",
        "# Save tokenizer metadata\n",
        "tokenizer_info = {\n",
        "    'vocab_size': VOCAB_SIZE,\n",
        "    'pad_id': PAD_ID,\n",
        "    'bos_id': BOS_ID,\n",
        "    'eos_id': EOS_ID,\n",
        "    'unk_id': UNK_ID,\n",
        "    'model_type': 'bpe',\n",
        "    'character_coverage': 1.0,\n",
        "    'special_tokens': ['[MASK]'],\n",
        "    'training_texts': len(all_texts)\n",
        "}\n",
        "\n",
        "with open('/content/urdu_files/tokenizer_info.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer_info, f)\n",
        "\n",
        "# Save vocabulary mapping\n",
        "vocab_mapping = {}\n",
        "for i in range(VOCAB_SIZE):\n",
        "    vocab_mapping[i] = tokenizer.id_to_piece(i)\n",
        "\n",
        "with open('/content/urdu_files/vocab_mapping.pkl', 'wb') as f:\n",
        "    pickle.dump(vocab_mapping, f)\n",
        "\n",
        "print(f\"âœ… Tokenizer trained: vocab size {VOCAB_SIZE}\")\n",
        "print(f\"ðŸ”¤ Training data: {len(all_texts)} Urdu texts\")\n",
        "print(f\"âœ… Tokenizer saved to /content/urdu_files/\")\n",
        "print(f\"âœ… Vocabulary mapping saved: {len(vocab_mapping)} tokens\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "421f7416",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "421f7416",
        "outputId": "01e26da9-a786-4552-953c-34ff09bde88c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ’¾ Saving training data to Colab...\n",
            "âœ… Saved training data:\n",
            "   ðŸ“ Original Urdu sentences: 20000\n",
            "   ðŸŽ­ Masked data: 3901 pairs\n",
            "   ðŸ“š Original data: 16000 pairs\n",
            "   ðŸ—‚ï¸ Total training data: 19901 pairs\n",
            "ðŸ’¾ All files saved to: /content/urdu_files/\n",
            "âœ… Masked data saved: /content/urdu_files/masked_20percent.tsv\n",
            "âœ… Original data saved: /content/urdu_files/original_80percent.tsv\n",
            "âœ… Combined supervised data: 19901 examples\n"
          ]
        }
      ],
      "source": [
        "# ðŸ’¾ SAVE TRAINING DATA TO COLAB\n",
        "print(\"ðŸ’¾ Saving training data to Colab...\")\n",
        "\n",
        "# Save all training data components\n",
        "with open('/content/urdu_files/urdu_sentences.pkl', 'wb') as f:\n",
        "    pickle.dump(urdu_sentences, f)\n",
        "\n",
        "# Convert to DataFrames and save as CSV/TSV\n",
        "masked_df = pd.DataFrame(masked_data)\n",
        "original_df = pd.DataFrame(original_data)\n",
        "all_training_df = pd.DataFrame(all_training_data)\n",
        "\n",
        "# Save as CSV/TSV files\n",
        "masked_df.to_csv('/content/urdu_files/masked_data.csv', index=False)\n",
        "original_df.to_csv('/content/urdu_files/original_data.csv', index=False)\n",
        "all_training_df.to_csv('/content/urdu_files/all_training_data.csv', index=False)\n",
        "\n",
        "print(f\"âœ… Saved training data:\")\n",
        "print(f\"   ðŸ“ Original Urdu sentences: {len(urdu_sentences)}\")\n",
        "print(f\"   ðŸŽ­ Masked data: {len(masked_data)} pairs\")\n",
        "print(f\"   ðŸ“š Original data: {len(original_data)} pairs\")\n",
        "print(f\"   ðŸ—‚ï¸ Total training data: {len(all_training_data)} pairs\")\n",
        "print(f\"ðŸ’¾ All files saved to: /content/urdu_files/\")\n",
        "\n",
        "# Save combined data for training\n",
        "all_supervised_data = []\n",
        "for item in masked_data:\n",
        "    all_supervised_data.append({'input': item['input'], 'target': item['target']})\n",
        "for item in original_data:\n",
        "    all_supervised_data.append({'input': item['input'], 'target': item['target']})\n",
        "\n",
        "with open('/content/urdu_files/all_supervised_data.pkl', 'wb') as f:\n",
        "    pickle.dump(all_supervised_data, f)\n",
        "\n",
        "print(f\"âœ… Masked data saved: /content/urdu_files/masked_20percent.tsv\")\n",
        "print(f\"âœ… Original data saved: /content/urdu_files/original_80percent.tsv\")\n",
        "print(f\"âœ… Combined supervised data: {len(all_supervised_data)} examples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "92454b85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92454b85",
        "outputId": "1b9c3002-baae-48ef-af9f-18060c5f681c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ—ï¸ Custom Transformer Encoder-Decoder Built:\n",
            "   ðŸ”¤ Vocabulary Size: 8,000\n",
            "   ðŸ“ Embedding Dimensions: 256\n",
            "   ðŸ§  Multi-Head Attention Heads: 2\n",
            "   ðŸ“š Encoder Layers: 2\n",
            "   ðŸ“– Decoder Layers: 2\n",
            "   ðŸ”¢ Total Parameters: 7,995,200\n",
            "   ðŸŽ¯ Trainable Parameters: 7,995,200\n",
            "   ï¿½ Dropout: 0.1\n",
            "âœ… Architecture matches assignment specifications exactly!\n"
          ]
        }
      ],
      "source": [
        "# ðŸ—ï¸ CUSTOM TRANSFORMER ENCODER-DECODER FROM SCRATCH\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"Custom Multi-Head Attention with Key, Query, Value concept\"\"\"\n",
        "    def __init__(self, d_model, heads):\n",
        "        super().__init__()\n",
        "        assert d_model % heads == 0\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.heads = heads\n",
        "        self.d_k = d_model // heads\n",
        "\n",
        "        # Linear projections for Query, Key, Value\n",
        "        self.w_q = nn.Linear(d_model, d_model)\n",
        "        self.w_k = nn.Linear(d_model, d_model)\n",
        "        self.w_v = nn.Linear(d_model, d_model)\n",
        "        self.w_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        \"\"\"Implement scaled dot-product attention\"\"\"\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        attention_weights = F.softmax(scores, dim=-1)\n",
        "        output = torch.matmul(attention_weights, V)\n",
        "\n",
        "        return output, attention_weights\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        # Linear projections in batch from d_model => h x d_k\n",
        "        Q = self.w_q(query).view(batch_size, -1, self.heads, self.d_k).transpose(1, 2)\n",
        "        K = self.w_k(key).view(batch_size, -1, self.heads, self.d_k).transpose(1, 2)\n",
        "        V = self.w_v(value).view(batch_size, -1, self.heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Apply attention on all projected vectors in batch\n",
        "        attn_output, self.attention_weights = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "\n",
        "        # Concatenate heads and put through final linear layer\n",
        "        attn_output = attn_output.transpose(1, 2).contiguous().view(\n",
        "            batch_size, -1, self.d_model)\n",
        "\n",
        "        return self.w_o(attn_output)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"Sinusoidal positional encoding\"\"\"\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
        "                            -(math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    \"\"\"Position-wise Feed-Forward Network\"\"\"\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.dropout(F.relu(self.linear1(x))))\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    \"\"\"Single Transformer Encoder Layer\"\"\"\n",
        "    def __init__(self, d_model, heads, d_ff, dropout):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, heads)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        # Self-attention with residual connection\n",
        "        attn_output = self.self_attn(x, x, x, src_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "\n",
        "        # Feed-forward with residual connection\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "\n",
        "        return x\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    \"\"\"Single Transformer Decoder Layer\"\"\"\n",
        "    def __init__(self, d_model, heads, d_ff, dropout):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, heads)\n",
        "        self.enc_attn = MultiHeadAttention(d_model, heads)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        # Masked self-attention\n",
        "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "\n",
        "        # Encoder-decoder attention\n",
        "        attn_output = self.enc_attn(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(attn_output))\n",
        "\n",
        "        # Feed-forward\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "\n",
        "        return x\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    \"\"\"Transformer Encoder Stack\"\"\"\n",
        "    def __init__(self, layer, num_layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([layer for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return x\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    \"\"\"Transformer Decoder Stack\"\"\"\n",
        "    def __init__(self, layer, num_layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([layer for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, enc_output, src_mask, tgt_mask)\n",
        "        return x\n",
        "\n",
        "class UrduTransformer(nn.Module):\n",
        "    \"\"\"Complete Transformer Encoder-Decoder for Urdu Chatbot\"\"\"\n",
        "    def __init__(self, vocab_size, d_model=256, heads=2, num_encoder_layers=2,\n",
        "                 num_decoder_layers=2, d_ff=1024, max_len=512, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        # Embeddings\n",
        "        self.src_embed = nn.Embedding(vocab_size, d_model)\n",
        "        self.tgt_embed = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "\n",
        "        # Encoder\n",
        "        encoder_layer = EncoderLayer(d_model, heads, d_ff, dropout)\n",
        "        self.encoder = TransformerEncoder(encoder_layer, num_encoder_layers)\n",
        "\n",
        "        # Decoder\n",
        "        decoder_layer = DecoderLayer(d_model, heads, d_ff, dropout)\n",
        "        self.decoder = TransformerDecoder(decoder_layer, num_decoder_layers)\n",
        "\n",
        "        # Output projection\n",
        "        self.output_projection = nn.Linear(d_model, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Initialize parameters\n",
        "        self._init_parameters()\n",
        "\n",
        "    def _init_parameters(self):\n",
        "        \"\"\"Initialize parameters with Xavier uniform\"\"\"\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    def create_masks(self, src, tgt):\n",
        "        \"\"\"Create attention masks\"\"\"\n",
        "        # Source padding mask\n",
        "        src_mask = (src != PAD_ID).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # Target padding mask\n",
        "        tgt_mask = (tgt != PAD_ID).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # Target sequence mask (causal mask)\n",
        "        seq_len = tgt.size(1)\n",
        "        nopeak_mask = torch.tril(torch.ones(seq_len, seq_len, device=tgt.device)).bool()\n",
        "        tgt_mask = tgt_mask & nopeak_mask\n",
        "\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        # Create masks\n",
        "        src_mask, tgt_mask = self.create_masks(src, tgt)\n",
        "\n",
        "        # Encoder\n",
        "        src_embedded = self.dropout(self.pos_encoding(self.src_embed(src) * math.sqrt(self.d_model)))\n",
        "        enc_output = self.encoder(src_embedded, src_mask)\n",
        "\n",
        "        # Decoder\n",
        "        tgt_embedded = self.dropout(self.pos_encoding(self.tgt_embed(tgt) * math.sqrt(self.d_model)))\n",
        "        dec_output = self.decoder(tgt_embedded, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        # Output projection\n",
        "        output = self.output_projection(dec_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Initialize the custom Transformer model with exact specifications\n",
        "model = UrduTransformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    d_model=256,           # Embedding dimensions as specified\n",
        "    heads=2,               # 2 Multi-head attention heads as required\n",
        "    num_encoder_layers=2,  # 2 Encoder layers as specified\n",
        "    num_decoder_layers=2,  # 2 Decoder layers as specified\n",
        "    d_ff=1024,            # Feed-forward dimension (4x d_model)\n",
        "    max_len=512,\n",
        "    dropout=0.1           # Dropout as specified\n",
        ").to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"ðŸ—ï¸ Custom Transformer Encoder-Decoder Built:\")\n",
        "print(f\"   ðŸ”¤ Vocabulary Size: {VOCAB_SIZE:,}\")\n",
        "print(f\"   ðŸ“ Embedding Dimensions: 256\")\n",
        "print(f\"   ðŸ§  Multi-Head Attention Heads: 2\")\n",
        "print(f\"   ðŸ“š Encoder Layers: 2\")\n",
        "print(f\"   ðŸ“– Decoder Layers: 2\")\n",
        "print(f\"   ðŸ”¢ Total Parameters: {total_params:,}\")\n",
        "print(f\"   ðŸŽ¯ Trainable Parameters: {trainable_params:,}\")\n",
        "print(f\"   ï¿½ Dropout: 0.1\")\n",
        "print(f\"âœ… Architecture matches assignment specifications exactly!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "16735756",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16735756",
        "outputId": "a7501d28-5d6a-4725-bc38-b52a606783d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ’¾ Saving model components to Colab...\n",
            "âœ… Source embedding weights saved: (8000, 256)\n",
            "âœ… Target embedding weights saved: (8000, 256)\n",
            "âœ… Positional encoding saved: (1, 512, 256)\n",
            "âœ… Encoder layers saved: 32 components\n",
            "âœ… Decoder layers saved: 52 components\n",
            "âœ… Complete transformer components saved\n",
            "ðŸ“Š Model Architecture:\n",
            "   ðŸ”¤ Source Vocab Size: 8,000\n",
            "   ðŸ”¤ Target Vocab Size: 8,000\n",
            "   ðŸ“ Embedding Dimension: 256\n",
            "   ðŸ§  Attention Heads: 2\n",
            "   ðŸ“š Encoder/Decoder Layers: 2 each\n"
          ]
        }
      ],
      "source": [
        "# ðŸ’¾ SAVE MODEL COMPONENTS TO COLAB\n",
        "print(\"ðŸ’¾ Saving model components to Colab...\")\n",
        "\n",
        "# Save source embedding weights (correct attribute name)\n",
        "src_embedding_weights = model.src_embed.weight.detach().cpu().numpy()\n",
        "with open('/content/urdu_files/src_embedding_weights.pkl', 'wb') as f:\n",
        "    pickle.dump(src_embedding_weights, f)\n",
        "\n",
        "# Save target embedding weights (correct attribute name)\n",
        "tgt_embedding_weights = model.tgt_embed.weight.detach().cpu().numpy()\n",
        "with open('/content/urdu_files/tgt_embedding_weights.pkl', 'wb') as f:\n",
        "    pickle.dump(tgt_embedding_weights, f)\n",
        "\n",
        "# Save positional encoding (correct attribute path)\n",
        "pos_encoding = model.pos_encoding.pe.detach().cpu().numpy()\n",
        "with open('/content/urdu_files/positional_encoding.pkl', 'wb') as f:\n",
        "    pickle.dump(pos_encoding, f)\n",
        "\n",
        "# Save encoder state\n",
        "encoder_state = model.encoder.state_dict()\n",
        "with open('/content/urdu_files/encoder_layers.pkl', 'wb') as f:\n",
        "    pickle.dump(encoder_state, f)\n",
        "\n",
        "# Save decoder state\n",
        "decoder_state = model.decoder.state_dict()\n",
        "with open('/content/urdu_files/decoder_layers.pkl', 'wb') as f:\n",
        "    pickle.dump(decoder_state, f)\n",
        "\n",
        "# Save complete transformer components\n",
        "transformer_components = {\n",
        "    'src_embedding_weights': src_embedding_weights,\n",
        "    'tgt_embedding_weights': tgt_embedding_weights,\n",
        "    'positional_encoding': pos_encoding,\n",
        "    'encoder_state_dict': encoder_state,\n",
        "    'decoder_state_dict': decoder_state,\n",
        "    'output_projection_state': model.output_projection.state_dict(),\n",
        "    'model_config': {\n",
        "        'vocab_size': VOCAB_SIZE,\n",
        "        'd_model': 256,\n",
        "        'heads': 2,\n",
        "        'encoder_layers': 2,\n",
        "        'decoder_layers': 2,\n",
        "        'max_len': 512,\n",
        "        'dropout': 0.1,\n",
        "        'total_params': total_params\n",
        "    },\n",
        "    'architecture_details': {\n",
        "        'type': 'Custom Transformer Encoder-Decoder',\n",
        "        'src_embed_shape': src_embedding_weights.shape,\n",
        "        'tgt_embed_shape': tgt_embedding_weights.shape,\n",
        "        'pos_encoding_shape': pos_encoding.shape,\n",
        "        'custom_multihead_attention': True,\n",
        "        'sinusoidal_positional_encoding': True\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('/content/urdu_files/transformer_components.pkl', 'wb') as f:\n",
        "    pickle.dump(transformer_components, f)\n",
        "\n",
        "print(f\"âœ… Source embedding weights saved: {src_embedding_weights.shape}\")\n",
        "print(f\"âœ… Target embedding weights saved: {tgt_embedding_weights.shape}\")\n",
        "print(f\"âœ… Positional encoding saved: {pos_encoding.shape}\")\n",
        "print(f\"âœ… Encoder layers saved: {len(encoder_state)} components\")\n",
        "print(f\"âœ… Decoder layers saved: {len(decoder_state)} components\")\n",
        "print(f\"âœ… Complete transformer components saved\")\n",
        "print(f\"ðŸ“Š Model Architecture:\")\n",
        "print(f\"   ðŸ”¤ Source Vocab Size: {VOCAB_SIZE:,}\")\n",
        "print(f\"   ðŸ”¤ Target Vocab Size: {VOCAB_SIZE:,}\")\n",
        "print(f\"   ðŸ“ Embedding Dimension: 256\")\n",
        "print(f\"   ðŸ§  Attention Heads: 2\")\n",
        "print(f\"   ðŸ“š Encoder/Decoder Layers: 2 each\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0867a169",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0867a169",
        "outputId": "d7892bc5-a01f-44ea-ef57-03f4fa758c36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ’¾ Saving training splits to Colab...\n",
            "âœ… Training data saved: /content/urdu_files/training_80percent.pkl\n",
            "âœ… Validation data saved: /content/urdu_files/validation_20percent.pkl\n",
            "ðŸ“¦ DataLoaders created:\n",
            "   ðŸš‚ Train batches: 498\n",
            "   ðŸ” Validation batches: 63\n"
          ]
        }
      ],
      "source": [
        "# ðŸ’¾ SAVE TRAINING DATA TO COLAB\n",
        "print(\"ðŸ’¾ Saving training splits to Colab...\")\n",
        "\n",
        "# Save training data (80%)\n",
        "with open('/content/urdu_files/training_80percent.pkl', 'wb') as f:\n",
        "    pickle.dump(train_data, f)\n",
        "\n",
        "# Save validation data (20%)\n",
        "with open('/content/urdu_files/validation_20percent.pkl', 'wb') as f:\n",
        "    pickle.dump(val_data, f)\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = UrduDataset(train_data, tokenizer)\n",
        "val_dataset = UrduDataset(val_data, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn, pin_memory=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn, pin_memory=False)\n",
        "\n",
        "print(f\"âœ… Training data saved: /content/urdu_files/training_80percent.pkl\")\n",
        "print(f\"âœ… Validation data saved: /content/urdu_files/validation_20percent.pkl\")\n",
        "print(f\"ðŸ“¦ DataLoaders created:\")\n",
        "print(f\"   ðŸš‚ Train batches: {len(train_loader)}\")\n",
        "print(f\"   ðŸ” Validation batches: {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6588c63e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6588c63e",
        "outputId": "0f41932e-c7b2-4498-87c0-61420926b526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ Setting up basic training components...\n",
            "âœ… Basic training setup completed!\n",
            "   ðŸ“¦ Batch size: 32\n",
            "   ðŸ”§ Learning rate: 0.0001\n",
            "   ðŸ’§ Dropout: 0.1\n",
            "   ðŸŽ¯ Ready for enhanced training or fallback training\n"
          ]
        }
      ],
      "source": [
        "# ðŸŽ¯ BASIC TRAINING SETUP (Fallback for Enhanced Training)\n",
        "print(\"ðŸŽ¯ Setting up basic training components...\")\n",
        "\n",
        "# Create basic data splits if not already created\n",
        "if 'train_data' not in locals() or 'val_data' not in locals() or 'test_data' not in locals():\n",
        "    total_size = len(all_training_data)\n",
        "    train_size, val_size = int(total_size * 0.8), int(total_size * 0.1)\n",
        "    train_data = all_training_data[:train_size]\n",
        "    val_data = all_training_data[train_size:train_size + val_size]\n",
        "    test_data = all_training_data[train_size + val_size:]\n",
        "    print(f\"ðŸ“Š Created splits: Train {len(train_data)} | Val {len(val_data)} | Test {len(test_data)}\")\n",
        "\n",
        "# Basic training constants\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-4\n",
        "DROPOUT = 0.1\n",
        "\n",
        "# Basic loss and evaluation functions (for enhanced training fallback)\n",
        "def basic_masked_loss(pred, target, mask):\n",
        "    \"\"\"Basic masked loss function\"\"\"\n",
        "    pred_flat = pred.reshape(-1, VOCAB_SIZE)\n",
        "    target_flat = target.reshape(-1)\n",
        "    mask_flat = mask.reshape(-1)\n",
        "\n",
        "    if mask_flat.any():\n",
        "        return F.cross_entropy(pred_flat[mask_flat], target_flat[mask_flat], ignore_index=PAD_ID)\n",
        "    return torch.tensor(0.0, device=pred.device, requires_grad=True)\n",
        "\n",
        "def basic_masked_accuracy(pred, target, mask):\n",
        "    \"\"\"Basic masked accuracy calculation\"\"\"\n",
        "    pred_tokens = torch.argmax(pred, dim=-1).reshape(-1)\n",
        "    mask_flat = mask.reshape(-1)\n",
        "    if mask_flat.any():\n",
        "        correct = (pred_tokens[mask_flat] == target.reshape(-1)[mask_flat]).sum().item()\n",
        "        return correct / mask_flat.sum().item(), mask_flat.sum().item()\n",
        "    return 0.0, 0\n",
        "\n",
        "print(f\"âœ… Basic training setup completed!\")\n",
        "print(f\"   ðŸ“¦ Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   ðŸ”§ Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"   ðŸ’§ Dropout: {DROPOUT}\")\n",
        "print(f\"   ðŸŽ¯ Ready for enhanced training or fallback training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2936ee2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2936ee2f",
        "outputId": "d3306acb-50ac-4468-9639-20418fc1d04c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§  Creating enhanced context representation with masking technique...\n",
            "ðŸš€ Starting enhanced context representation creation...\n",
            "ðŸ”„ Creating enhanced contextual representation with unique probability-based pairing...\n",
            "ðŸ“Š Created 7682 masked contexts from 2000 sentences\n",
            "ðŸŽ¯ Found 2000 unique sentences for probability pairing\n",
            "ðŸ“ˆ Calculating embeddings for unique sentence probability distribution...\n",
            "ðŸ“Š Calculating contextual embeddings for deeper semantic understanding...\n",
            "âœ… Created contextual embeddings:\n",
            "   ðŸ“Š TF-IDF dimensions: (2000, 8000)\n",
            "   ðŸŽ¯ Contextual features: (2000, 7)\n",
            "ðŸŽ¯ Creating unique high-probability sentence pairs...\n",
            "ðŸŽ¯ Calculating enhanced contextual probability distributions...\n",
            "ðŸ§  Using enhanced contextual similarity calculation...\n",
            "ðŸ“Š Found 46995 contextually relevant pairs\n",
            "âœ… Created 209 contextually relevant pairs\n",
            "ðŸ”„ Adding contextually diverse pairs...\n",
            "âœ… Added contextual diversity pairs, total: 237\n",
            "ðŸŽ­ Creating masked reconstruction pairs...\n",
            "ðŸš€ Creating enhanced contextual pairs with probability mapping...\n",
            "âœ… Created 7434 unique high-quality pairs:\n",
            "   ðŸŽ­ Reconstruction pairs: 7630\n",
            "   ðŸ”— Enhanced contextual pairs: 282\n",
            "   ðŸŽ¯ Unique probability-based pairs: 237\n",
            "   ðŸ“Š Final deduplicated pairs: 7434\n",
            "ðŸ“ˆ Quality distribution:\n",
            "   ðŸ† High probability (>0.5): 7199\n",
            "   ðŸ“ˆ Medium probability (0.3-0.5): 187\n",
            "   ðŸ“Š Average probability: 0.978\n",
            "\n",
            "ðŸ“ˆ Probability Distribution Statistics:\n",
            "   ðŸ“Š Mean probability: 0.980\n",
            "   ðŸ“Š Std probability: 0.118\n",
            "   ðŸ“Š Max probability: 1.000\n",
            "   ðŸ“Š Min probability: 0.201\n",
            "\n",
            "ðŸ“ Example Enhanced Pairs:\n",
            "\n",
            "1. Type: reconstruction | Prob: 1.000\n",
            "   ðŸ”¤ Input:  [MASK] [MASK] ÛÛŒ Ø®ÛŒØ§Ù„ÛŒ Ù¾Ù„Ø§Ùˆ Ø¨Ù†Ø§ØªØ§ ÛÙˆÚº...\n",
            "   ðŸŽ¯ Target: Ú©Ø¨Ú¾ÛŒ Ú©Ø¨Ú¾Ø§Ø± ÛÛŒ Ø®ÛŒØ§Ù„ÛŒ Ù¾Ù„Ø§Ùˆ Ø¨Ù†Ø§ØªØ§ ÛÙˆÚº...\n",
            "\n",
            "2. Type: reconstruction | Prob: 1.000\n",
            "   ðŸ”¤ Input:  [MASK] Ú©Ø¨Ú¾Ø§Ø± ÛÛŒ Ø®ÛŒØ§Ù„ÛŒ Ù¾Ù„Ø§Ùˆ [MASK] ÛÙˆÚº...\n",
            "   ðŸŽ¯ Target: Ú©Ø¨Ú¾ÛŒ Ú©Ø¨Ú¾Ø§Ø± ÛÛŒ Ø®ÛŒØ§Ù„ÛŒ Ù¾Ù„Ø§Ùˆ Ø¨Ù†Ø§ØªØ§ ÛÙˆÚº...\n",
            "\n",
            "3. Type: reconstruction | Prob: 1.000\n",
            "   ðŸ”¤ Input:  Ú©Ø¨Ú¾ÛŒ [MASK] ÛÛŒ Ø®ÛŒØ§Ù„ÛŒ Ù¾Ù„Ø§Ùˆ [MASK] ÛÙˆÚº...\n",
            "   ðŸŽ¯ Target: Ú©Ø¨Ú¾ÛŒ Ú©Ø¨Ú¾Ø§Ø± ÛÛŒ Ø®ÛŒØ§Ù„ÛŒ Ù¾Ù„Ø§Ùˆ Ø¨Ù†Ø§ØªØ§ ÛÙˆÚº...\n",
            "\n",
            "4. Type: reconstruction | Prob: 1.000\n",
            "   ðŸ”¤ Input:  Ú©Ø¨Ú¾ÛŒ Ú©Ø¨Ú¾Ø§Ø± [MASK] [MASK] [MASK] Ø¨Ù†Ø§ØªØ§ ÛÙˆÚº...\n",
            "   ðŸŽ¯ Target: Ú©Ø¨Ú¾ÛŒ Ú©Ø¨Ú¾Ø§Ø± ÛÛŒ Ø®ÛŒØ§Ù„ÛŒ Ù¾Ù„Ø§Ùˆ Ø¨Ù†Ø§ØªØ§ ÛÙˆÚº...\n",
            "\n",
            "5. Type: reconstruction | Prob: 1.000\n",
            "   ðŸ”¤ Input:  [MASK] Ù¾Ú¾Ø± [MASK] ÛÛŒ Ú©Û Ù¾Ø§Ú©Ø³ØªØ§Ù† Ø¨Ú¾ÛŒ ÛÙˆ...\n",
            "   ðŸŽ¯ Target: Ø§ÙˆØ± Ù¾Ú¾Ø± Ù…Ù…Ú©Ù† ÛÛŒ Ú©Û Ù¾Ø§Ú©Ø³ØªØ§Ù† Ø¨Ú¾ÛŒ ÛÙˆ...\n",
            "\n",
            "âœ… Enhanced context representation completed!\n",
            "ðŸ“Š Total enhanced pairs: 7434\n"
          ]
        }
      ],
      "source": [
        "# ðŸ§  ENHANCED CONTEXT REPRESENTATION WITH MASKING TECHNIQUE\n",
        "print(\"ðŸ§  Creating enhanced context representation with masking technique...\")\n",
        "\n",
        "class ContextRepresentationMaker:\n",
        "    \"\"\"\n",
        "    Advanced context representation using masking and probability distribution\n",
        "    for creating high-quality sentence pairs for chatbot training\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sentences, tokenizer, device):\n",
        "        self.sentences = sentences\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "        self.mask_strategies = ['random', 'noun_verb', 'important_words', 'context_dependent']\n",
        "\n",
        "    def create_masked_contexts(self, sentence, mask_ratio=0.3):\n",
        "        \"\"\"Create multiple masked versions for better context representation\"\"\"\n",
        "        words = sentence.split()\n",
        "        if len(words) < 3:\n",
        "            return [sentence]\n",
        "\n",
        "        masked_versions = []\n",
        "\n",
        "        # Strategy 1: Random masking\n",
        "        for _ in range(2):\n",
        "            mask_count = max(1, int(len(words) * mask_ratio))\n",
        "            mask_indices = np.random.choice(len(words), mask_count, replace=False)\n",
        "            masked_words = words.copy()\n",
        "            for idx in mask_indices:\n",
        "                masked_words[idx] = \"[MASK]\"\n",
        "            masked_versions.append(' '.join(masked_words))\n",
        "\n",
        "        # Strategy 2: Important word masking (longer words, likely content words)\n",
        "        important_indices = [i for i, word in enumerate(words) if len(word) > 3]\n",
        "        if important_indices:\n",
        "            mask_count = max(1, min(len(important_indices), int(len(words) * mask_ratio)))\n",
        "            mask_indices = np.random.choice(important_indices, mask_count, replace=False)\n",
        "            masked_words = words.copy()\n",
        "            for idx in mask_indices:\n",
        "                masked_words[idx] = \"[MASK]\"\n",
        "            masked_versions.append(' '.join(masked_words))\n",
        "\n",
        "        # Strategy 3: Sequential masking (mask consecutive words)\n",
        "        if len(words) >= 4:\n",
        "            start_idx = np.random.randint(0, len(words) - 2)\n",
        "            mask_length = min(3, len(words) - start_idx)\n",
        "            masked_words = words.copy()\n",
        "            for i in range(start_idx, start_idx + mask_length):\n",
        "                masked_words[i] = \"[MASK]\"\n",
        "            masked_versions.append(' '.join(masked_words))\n",
        "\n",
        "        return masked_versions\n",
        "\n",
        "    def calculate_sentence_embeddings(self, sentences):\n",
        "        \"\"\"\n",
        "        Enhanced contextual embeddings using multiple methods for deeper understanding\n",
        "        \"\"\"\n",
        "        print(\"ðŸ“Š Calculating contextual embeddings for deeper semantic understanding...\")\n",
        "\n",
        "        # Clean sentences for analysis\n",
        "        clean_sentences = []\n",
        "        sentence_features = []\n",
        "\n",
        "        for sent in sentences:\n",
        "            # Remove [MASK] tokens and clean\n",
        "            clean_sent = sent.replace('[MASK]', '').strip()\n",
        "            clean_sent = ' '.join(clean_sent.split())  # Remove extra spaces\n",
        "            if clean_sent:\n",
        "                clean_sentences.append(clean_sent)\n",
        "\n",
        "                # Extract contextual features for each sentence\n",
        "                words = clean_sent.split()\n",
        "                features = {\n",
        "                    'length': len(words),\n",
        "                    'avg_word_length': sum(len(w) for w in words) / len(words) if words else 0,\n",
        "                    'question_words': sum(1 for w in words if w in ['Ú©ÛŒØ§', 'Ú©ÛŒØ³Û’', 'Ú©ÛØ§Úº', 'Ú©Ø¨', 'Ú©ÙˆÙ†', 'Ú©ØªÙ†Ø§']),\n",
        "                    'greeting_words': sum(1 for w in words if w in ['Ø³Ù„Ø§Ù…', 'Ø¢Ø¯Ø§Ø¨', 'Ø§Ù„Ø³Ù„Ø§Ù…']),\n",
        "                    'emotional_words': sum(1 for w in words if w in ['Ø®ÙˆØ´', 'ØºÙ…', 'Ù…Ø­Ø¨Øª', 'Ù†ÙØ±Øª', 'Ø®ÙˆØ´ÛŒ']),\n",
        "                    'action_words': sum(1 for w in words if w.endswith('ÛŒÚº') or w.endswith('Û’') or w.endswith('ØªÛ’')),\n",
        "                    'formal_words': sum(1 for w in words if w in ['Ø¢Ù¾', 'Ø¬Ù†Ø§Ø¨', 'ØµØ§Ø­Ø¨', 'Ù…Ø­ØªØ±Ù…'])\n",
        "                }\n",
        "                sentence_features.append(features)\n",
        "            else:\n",
        "                clean_sentences.append(sent)\n",
        "                sentence_features.append({'length': 0, 'avg_word_length': 0, 'question_words': 0,\n",
        "                                        'greeting_words': 0, 'emotional_words': 0, 'action_words': 0, 'formal_words': 0})\n",
        "\n",
        "        # Enhanced TF-IDF with contextual n-grams\n",
        "        vectorizer = TfidfVectorizer(\n",
        "            max_features=8000,  # Increased for better context capture\n",
        "            min_df=1,           # Lower threshold for rare but meaningful words\n",
        "            max_df=0.9,         # Allow more common words for context\n",
        "            ngram_range=(1, 3), # Include trigrams for better context\n",
        "            analyzer='word',\n",
        "            sublinear_tf=True   # Better handling of frequent terms\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            # Primary TF-IDF embeddings\n",
        "            tfidf_matrix = vectorizer.fit_transform(clean_sentences)\n",
        "\n",
        "            # Create contextual feature matrix\n",
        "            feature_matrix = np.array([[f['length'], f['avg_word_length'], f['question_words'],\n",
        "                                      f['greeting_words'], f['emotional_words'], f['action_words'],\n",
        "                                      f['formal_words']] for f in sentence_features])\n",
        "\n",
        "            # Normalize feature matrix\n",
        "            from sklearn.preprocessing import StandardScaler\n",
        "            scaler = StandardScaler()\n",
        "            normalized_features = scaler.fit_transform(feature_matrix)\n",
        "\n",
        "            print(f\"âœ… Created contextual embeddings:\")\n",
        "            print(f\"   ðŸ“Š TF-IDF dimensions: {tfidf_matrix.shape}\")\n",
        "            print(f\"   ðŸŽ¯ Contextual features: {normalized_features.shape}\")\n",
        "\n",
        "            return tfidf_matrix, vectorizer, normalized_features, sentence_features\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Enhanced embeddings failed, using simple method: {e}\")\n",
        "            return None, None, None, sentence_features\n",
        "\n",
        "    def calculate_probability_distribution(self, sentences, embeddings=None, contextual_features=None, sentence_features=None):\n",
        "        \"\"\"\n",
        "        Enhanced contextual probability distribution for unique sentence pairing\n",
        "        Uses semantic similarity + contextual features for deeper understanding\n",
        "        \"\"\"\n",
        "        print(\"ðŸŽ¯ Calculating enhanced contextual probability distributions...\")\n",
        "\n",
        "        sentence_pairs = []\n",
        "        similarity_scores = []\n",
        "        used_targets = set()\n",
        "\n",
        "        if embeddings is not None and contextual_features is not None:\n",
        "            print(\"ðŸ§  Using enhanced contextual similarity calculation...\")\n",
        "\n",
        "            # Calculate semantic similarity matrix\n",
        "            semantic_similarity = cosine_similarity(embeddings)\n",
        "\n",
        "            # Calculate contextual feature similarity\n",
        "            contextual_similarity = cosine_similarity(contextual_features)\n",
        "\n",
        "            # Create all possible pairs with enhanced contextual scoring\n",
        "            all_possible_pairs = []\n",
        "\n",
        "            for i, sent1 in enumerate(sentences):\n",
        "                sent1_features = sentence_features[i] if sentence_features else {}\n",
        "\n",
        "                for j, sent2 in enumerate(sentences):\n",
        "                    if i != j:  # Never pair with self\n",
        "                        sent2_features = sentence_features[j] if sentence_features else {}\n",
        "\n",
        "                        # STRICT RULE: Prevent pairing with identical or very similar sentences\n",
        "                        sent1_clean = sent1.lower().strip()\n",
        "                        sent2_clean = sent2.lower().strip()\n",
        "\n",
        "                        # Skip if sentences are identical\n",
        "                        if sent1_clean == sent2_clean:\n",
        "                            continue\n",
        "\n",
        "                        # Skip if sentences are too similar (>80% word overlap)\n",
        "                        words1 = set(sent1_clean.split())\n",
        "                        words2 = set(sent2_clean.split())\n",
        "\n",
        "                        if len(words1) > 0 and len(words2) > 0:\n",
        "                            word_overlap = len(words1.intersection(words2))\n",
        "                            similarity_ratio = word_overlap / min(len(words1), len(words2))\n",
        "\n",
        "                            if similarity_ratio > 0.8:  # Skip very similar sentences\n",
        "                                continue\n",
        "\n",
        "                        # Base semantic similarity\n",
        "                        semantic_score = semantic_similarity[i][j]\n",
        "\n",
        "                        # PENALTY for high semantic similarity (we want different sentences)\n",
        "                        if semantic_score > 0.7:\n",
        "                            semantic_score = semantic_score * 0.3  # Heavy penalty for similar sentences\n",
        "\n",
        "                        # Contextual feature similarity\n",
        "                        contextual_score = contextual_similarity[i][j]\n",
        "\n",
        "                        # Enhanced contextual relevance scoring\n",
        "                        context_bonus = self._calculate_contextual_relevance(\n",
        "                            sent1, sent2, sent1_features, sent2_features\n",
        "                        )\n",
        "\n",
        "                        # Conversational flow bonus\n",
        "                        flow_bonus = self._calculate_conversational_flow(\n",
        "                            sent1, sent2, sent1_features, sent2_features\n",
        "                        )\n",
        "\n",
        "                        # DIVERSITY BONUS: Reward pairing different sentence types\n",
        "                        diversity_bonus = 0.0\n",
        "                        if self._are_sentences_diverse(sent1, sent2, sent1_features, sent2_features):\n",
        "                            diversity_bonus = 0.2\n",
        "\n",
        "                        # Combined contextual probability with diversity emphasis\n",
        "                        # Reduced semantic weight, increased contextual and diversity weights\n",
        "                        final_probability = (\n",
        "                            semantic_score * 0.2 +      # Reduced for diversity\n",
        "                            contextual_score * 0.3 +\n",
        "                            context_bonus * 0.3 +       # Increased for relevance\n",
        "                            flow_bonus * 0.1 +\n",
        "                            diversity_bonus * 0.1       # Bonus for diversity\n",
        "                        )\n",
        "\n",
        "                        # Only accept pairs with good contextual relevance but NOT high similarity\n",
        "                        if (final_probability > 0.15 and\n",
        "                            context_bonus > 0.1 and     # Must have contextual relevance\n",
        "                            semantic_score < 0.6):      # Must NOT be too similar\n",
        "\n",
        "                            all_possible_pairs.append({\n",
        "                                'input_idx': i,\n",
        "                                'target_idx': j,\n",
        "                                'input': sent1,\n",
        "                                'target': sent2,\n",
        "                                'probability': float(final_probability),\n",
        "                                'semantic_score': float(semantic_score),\n",
        "                                'contextual_score': float(contextual_score),\n",
        "                                'context_bonus': float(context_bonus),\n",
        "                                'flow_bonus': float(flow_bonus),\n",
        "                                'diversity_bonus': float(diversity_bonus),\n",
        "                                'pair_type': 'diverse_contextual'\n",
        "                            })\n",
        "\n",
        "            print(f\"ðŸ“Š Found {len(all_possible_pairs)} contextually relevant pairs\")\n",
        "\n",
        "            # Sort by contextual probability (highest first)\n",
        "            all_possible_pairs.sort(key=lambda x: x['probability'], reverse=True)\n",
        "\n",
        "            # Create unique optimal contextual pairings with STRICT diversity rules\n",
        "            used_inputs = set()\n",
        "            max_pairs_per_input = 2\n",
        "\n",
        "            for pair in all_possible_pairs:\n",
        "                input_count = sum(1 for p in sentence_pairs if p['input'] == pair['input'])\n",
        "\n",
        "                # STRICT ENHANCED selection criteria - NO similar sentences allowed\n",
        "                if (input_count < max_pairs_per_input and\n",
        "                    pair['target'] not in used_targets and\n",
        "                    pair['input'] != pair['target'] and           # Never same sentence\n",
        "                    pair['probability'] > 0.2 and                # Lower threshold for diversity\n",
        "                    pair['context_bonus'] > 0.1 and              # Must have contextual relevance\n",
        "                    pair['semantic_score'] < 0.6 and             # Must NOT be too similar\n",
        "                    not self._are_sentences_too_similar(pair['input'], pair['target'])):  # Final similarity check\n",
        "\n",
        "                    sentence_pairs.append({\n",
        "                        'input': pair['input'],\n",
        "                        'target': pair['target'],\n",
        "                        'probability': pair['probability'],\n",
        "                        'semantic_score': pair['semantic_score'],\n",
        "                        'contextual_score': pair['contextual_score'],\n",
        "                        'context_bonus': pair['context_bonus'],\n",
        "                        'flow_bonus': pair['flow_bonus'],\n",
        "                        'diversity_bonus': pair.get('diversity_bonus', 0.0),\n",
        "                        'pair_type': pair['pair_type'],\n",
        "                        'input_idx': pair['input_idx'],\n",
        "                        'target_idx': pair['target_idx']\n",
        "                    })\n",
        "\n",
        "                    used_targets.add(pair['target'])\n",
        "                    similarity_scores.append(pair['probability'])\n",
        "\n",
        "                    # Stop if we have enough high-quality diverse pairs\n",
        "                    if len(sentence_pairs) >= len(sentences) * 0.3:  # 30% for diverse quality\n",
        "                        break\n",
        "\n",
        "            print(f\"âœ… Created {len(sentence_pairs)} contextually relevant pairs\")\n",
        "\n",
        "        else:\n",
        "            # Enhanced fallback with contextual word analysis\n",
        "            print(\"ðŸ“ Using enhanced contextual word analysis...\")\n",
        "\n",
        "            all_possible_pairs = []\n",
        "            for i, sent1 in enumerate(sentences[:800]):  # Balanced efficiency\n",
        "                words1 = set(sent1.lower().split())\n",
        "                sent1_context = self._analyze_sentence_context(sent1)\n",
        "\n",
        "                for j, sent2 in enumerate(sentences):\n",
        "                    if i != j:  # Never pair with self\n",
        "                        words2 = set(sent2.lower().split())\n",
        "                        sent2_context = self._analyze_sentence_context(sent2)\n",
        "\n",
        "                        # STRICT RULE: Skip identical or very similar sentences\n",
        "                        if self._are_sentences_too_similar(sent1, sent2):\n",
        "                            continue\n",
        "\n",
        "                        # Enhanced similarity with contextual understanding\n",
        "                        word_overlap = len(words1.intersection(words2))\n",
        "                        total_words = len(words1.union(words2))\n",
        "\n",
        "                        if total_words > 0:\n",
        "                            # Base Jaccard similarity\n",
        "                            jaccard_sim = word_overlap / total_words\n",
        "\n",
        "                            # PENALTY for high word similarity (we want diverse pairs)\n",
        "                            if jaccard_sim > 0.6:\n",
        "                                jaccard_sim = jaccard_sim * 0.2  # Heavy penalty\n",
        "\n",
        "                            # Context type compatibility\n",
        "                            context_compatibility = self._calculate_context_compatibility(\n",
        "                                sent1_context, sent2_context\n",
        "                            )\n",
        "\n",
        "                            # Length and structure similarity\n",
        "                            length_sim = min(len(words1), len(words2)) / max(len(words1), len(words2))\n",
        "\n",
        "                            # Diversity bonus for different sentence types\n",
        "                            diversity_bonus = 0.0\n",
        "                            if self._are_sentences_diverse(sent1, sent2,\n",
        "                                                         {'length': len(words1)},\n",
        "                                                         {'length': len(words2)}):\n",
        "                                diversity_bonus = 0.3\n",
        "\n",
        "                            # Combined contextual score favoring diversity\n",
        "                            contextual_probability = (\n",
        "                                jaccard_sim * 0.2 +              # Reduced weight for similarity\n",
        "                                context_compatibility * 0.4 +    # Increased for context\n",
        "                                length_sim * 0.1 +               # Reduced weight\n",
        "                                diversity_bonus * 0.3            # Bonus for diversity\n",
        "                            )\n",
        "\n",
        "                            # Only accept diverse, contextually relevant pairs\n",
        "                            if (contextual_probability > 0.2 and\n",
        "                                context_compatibility > 0.2 and\n",
        "                                jaccard_sim < 0.5):  # Must NOT be too similar\n",
        "\n",
        "                                all_possible_pairs.append({\n",
        "                                    'input_idx': i,\n",
        "                                    'target_idx': j,\n",
        "                                    'input': sent1,\n",
        "                                    'target': sent2,\n",
        "                                    'probability': float(contextual_probability),\n",
        "                                    'context_compatibility': float(context_compatibility),\n",
        "                                    'diversity_bonus': float(diversity_bonus),\n",
        "                                    'pair_type': 'diverse_contextual_overlap'\n",
        "                                })\n",
        "\n",
        "            # Sort and create unique diverse contextual pairs\n",
        "            all_possible_pairs.sort(key=lambda x: x['probability'], reverse=True)\n",
        "\n",
        "            used_inputs = set()\n",
        "            for pair in all_possible_pairs[:min(400, len(all_possible_pairs))]:\n",
        "                if (pair['input'] not in used_inputs and\n",
        "                    pair['target'] not in used_targets and\n",
        "                    pair['input'] != pair['target'] and               # Never same sentence\n",
        "                    pair['probability'] > 0.25 and\n",
        "                    pair['context_compatibility'] > 0.2 and          # Good context compatibility\n",
        "                    not self._are_sentences_too_similar(pair['input'], pair['target'])):  # Final similarity check\n",
        "\n",
        "                    sentence_pairs.append({\n",
        "                        'input': pair['input'],\n",
        "                        'target': pair['target'],\n",
        "                        'probability': pair['probability'],\n",
        "                        'context_compatibility': pair['context_compatibility'],\n",
        "                        'diversity_bonus': pair.get('diversity_bonus', 0.0),\n",
        "                        'pair_type': pair['pair_type']\n",
        "                    })\n",
        "\n",
        "                    used_inputs.add(pair['input'])\n",
        "                    used_targets.add(pair['target'])\n",
        "                    similarity_scores.append(pair['probability'])\n",
        "\n",
        "        # Add contextually diverse pairs for comprehensive coverage\n",
        "        self._add_contextual_diversity_pairs(sentence_pairs, sentences, similarity_scores, used_targets)\n",
        "\n",
        "        return sentence_pairs, similarity_scores\n",
        "\n",
        "    def _calculate_contextual_relevance(self, sent1, sent2, features1, features2):\n",
        "        \"\"\"Calculate contextual relevance between two sentences\"\"\"\n",
        "        relevance_score = 0.0\n",
        "\n",
        "        # Question-Answer pairing\n",
        "        if features1.get('question_words', 0) > 0 and features2.get('question_words', 0) == 0:\n",
        "            relevance_score += 0.3  # Question to statement\n",
        "\n",
        "        # Greeting-Response pairing\n",
        "        if features1.get('greeting_words', 0) > 0 and features2.get('greeting_words', 0) > 0:\n",
        "            relevance_score += 0.2  # Greeting exchange\n",
        "\n",
        "        # Emotional context matching\n",
        "        if features1.get('emotional_words', 0) > 0 and features2.get('emotional_words', 0) > 0:\n",
        "            relevance_score += 0.15  # Emotional continuation\n",
        "\n",
        "        # Formality level matching\n",
        "        if features1.get('formal_words', 0) > 0 and features2.get('formal_words', 0) > 0:\n",
        "            relevance_score += 0.1  # Formal conversation\n",
        "\n",
        "        # Action-response patterns\n",
        "        if features1.get('action_words', 0) > 0:\n",
        "            relevance_score += 0.1  # Action context\n",
        "\n",
        "        return min(relevance_score, 0.5)  # Cap at 0.5\n",
        "\n",
        "    def _calculate_conversational_flow(self, sent1, sent2, features1, features2):\n",
        "        \"\"\"Calculate how well sentences flow in conversation\"\"\"\n",
        "        flow_score = 0.0\n",
        "\n",
        "        # Length compatibility (similar lengths flow better)\n",
        "        len_diff = abs(features1.get('length', 0) - features2.get('length', 0))\n",
        "        if len_diff <= 3:\n",
        "            flow_score += 0.2\n",
        "        elif len_diff <= 6:\n",
        "            flow_score += 0.1\n",
        "\n",
        "        # Question-answer flow\n",
        "        if ('Ú©ÛŒØ§' in sent1 or 'Ú©ÛŒØ³Û’' in sent1) and ('ÛÛ’' in sent2 or 'ÛÙˆÚº' in sent2):\n",
        "            flow_score += 0.3\n",
        "\n",
        "        # Greeting flow patterns\n",
        "        if 'Ø³Ù„Ø§Ù…' in sent1 and ('Ø³Ù„Ø§Ù…' in sent2 or 'Ø®ÙˆØ´' in sent2):\n",
        "            flow_score += 0.2\n",
        "\n",
        "        # Politeness flow\n",
        "        if 'Ø´Ú©Ø±ÛŒÛ' in sent1 and ('Ø®ÙˆØ´ÛŒ' in sent2 or 'Ú©ÙˆØ¦ÛŒ' in sent2):\n",
        "            flow_score += 0.2\n",
        "\n",
        "        return min(flow_score, 0.4)  # Cap at 0.4\n",
        "\n",
        "    def _analyze_sentence_context(self, sentence):\n",
        "        \"\"\"Analyze the contextual type of a sentence\"\"\"\n",
        "        words = sentence.lower().split()\n",
        "        context = {\n",
        "            'is_question': any(w in words for w in ['Ú©ÛŒØ§', 'Ú©ÛŒØ³Û’', 'Ú©ÛØ§Úº', 'Ú©Ø¨', 'Ú©ÙˆÙ†', 'Ú©ØªÙ†Ø§']),\n",
        "            'is_greeting': any(w in words for w in ['Ø³Ù„Ø§Ù…', 'Ø¢Ø¯Ø§Ø¨', 'Ø§Ù„Ø³Ù„Ø§Ù…']),\n",
        "            'is_emotional': any(w in words for w in ['Ø®ÙˆØ´', 'ØºÙ…', 'Ù…Ø­Ø¨Øª', 'Ø®ÙˆØ´ÛŒ', 'Ù¾Ø±ÛŒØ´Ø§Ù†']),\n",
        "            'is_formal': any(w in words for w in ['Ø¢Ù¾', 'Ø¬Ù†Ø§Ø¨', 'ØµØ§Ø­Ø¨', 'Ù…Ø­ØªØ±Ù…']),\n",
        "            'is_action': any(w.endswith('ÛŒÚº') or w.endswith('Û’') or w.endswith('ØªÛ’') for w in words),\n",
        "            'is_response': any(w in words for w in ['ÛØ§Úº', 'Ù†ÛÛŒÚº', 'Ø¬ÛŒ', 'Ù¹Ú¾ÛŒÚ©']),\n",
        "            'is_polite': any(w in words for w in ['Ø´Ú©Ø±ÛŒÛ', 'Ù…Ø¹Ø°Ø±Øª', 'Ø¨Ø±Ø§Ø¦Û’ Ú©Ø±Ù…'])\n",
        "        }\n",
        "        return context\n",
        "\n",
        "    def _calculate_context_compatibility(self, context1, context2):\n",
        "        \"\"\"Calculate how compatible two sentence contexts are\"\"\"\n",
        "        compatibility = 0.0\n",
        "\n",
        "        # Question-answer compatibility\n",
        "        if context1['is_question'] and not context2['is_question']:\n",
        "            compatibility += 0.4  # Good Q-A flow\n",
        "\n",
        "        # Greeting compatibility\n",
        "        if context1['is_greeting'] and (context2['is_greeting'] or context2['is_response']):\n",
        "            compatibility += 0.3\n",
        "\n",
        "        # Emotional compatibility\n",
        "        if context1['is_emotional'] and context2['is_emotional']:\n",
        "            compatibility += 0.2\n",
        "\n",
        "        # Formality compatibility\n",
        "        if context1['is_formal'] == context2['is_formal']:\n",
        "            compatibility += 0.1\n",
        "\n",
        "        # Politeness flow\n",
        "        if context1['is_polite'] and context2['is_response']:\n",
        "            compatibility += 0.2\n",
        "\n",
        "        return min(compatibility, 0.6)  # Cap at 0.6\n",
        "\n",
        "    def _are_sentences_diverse(self, sent1, sent2, features1, features2):\n",
        "        \"\"\"Check if two sentences are diverse enough for good pairing\"\"\"\n",
        "        # Length diversity\n",
        "        len1 = features1.get('length', 0)\n",
        "        len2 = features2.get('length', 0)\n",
        "        length_diverse = abs(len1 - len2) >= 2\n",
        "\n",
        "        # Type diversity (question with statement, greeting with response, etc.)\n",
        "        words1 = sent1.lower().split()\n",
        "        words2 = sent2.lower().split()\n",
        "\n",
        "        # Question-statement diversity\n",
        "        is_question1 = any(w in words1 for w in ['Ú©ÛŒØ§', 'Ú©ÛŒØ³Û’', 'Ú©ÛØ§Úº', 'Ú©Ø¨'])\n",
        "        is_question2 = any(w in words2 for w in ['Ú©ÛŒØ§', 'Ú©ÛŒØ³Û’', 'Ú©ÛØ§Úº', 'Ú©Ø¨'])\n",
        "        type_diverse = is_question1 != is_question2\n",
        "\n",
        "        # Content diversity (different main words)\n",
        "        content_words1 = [w for w in words1 if len(w) > 3]\n",
        "        content_words2 = [w for w in words2 if len(w) > 3]\n",
        "\n",
        "        if content_words1 and content_words2:\n",
        "            content_overlap = len(set(content_words1).intersection(set(content_words2)))\n",
        "            content_diverse = content_overlap <= 1\n",
        "        else:\n",
        "            content_diverse = True\n",
        "\n",
        "        return length_diverse or type_diverse or content_diverse\n",
        "\n",
        "    def _are_sentences_too_similar(self, sent1, sent2):\n",
        "        \"\"\"Check if sentences are too similar to be paired\"\"\"\n",
        "        words1 = set(sent1.lower().split())\n",
        "        words2 = set(sent2.lower().split())\n",
        "\n",
        "        if len(words1) == 0 or len(words2) == 0:\n",
        "            return True\n",
        "\n",
        "        # Check exact match\n",
        "        if sent1.strip().lower() == sent2.strip().lower():\n",
        "            return True\n",
        "\n",
        "        # Check high word overlap\n",
        "        overlap = len(words1.intersection(words2))\n",
        "        total_unique = len(words1.union(words2))\n",
        "\n",
        "        if total_unique > 0:\n",
        "            similarity = overlap / total_unique\n",
        "            return similarity > 0.7  # Too similar if >70% word overlap\n",
        "\n",
        "        return False\n",
        "\n",
        "    def _add_contextual_diversity_pairs(self, sentence_pairs, sentences, similarity_scores, used_targets):\n",
        "        \"\"\"Add contextually diverse pairs for comprehensive coverage\"\"\"\n",
        "        print(\"ðŸ”„ Adding contextually diverse pairs...\")\n",
        "\n",
        "        unused_sentences = [sent for sent in sentences if sent not in used_targets]\n",
        "\n",
        "        if len(unused_sentences) > 0:\n",
        "            diversity_pairs = min(30, len(unused_sentences))\n",
        "\n",
        "            for i in range(diversity_pairs):\n",
        "                if i < len(unused_sentences):\n",
        "                    target_sent = unused_sentences[i]\n",
        "                    target_context = self._analyze_sentence_context(target_sent)\n",
        "\n",
        "                    # Find contextually compatible input\n",
        "                    best_input = None\n",
        "                    best_score = 0\n",
        "\n",
        "                    for sent in sentences[:50]:  # Sample from first 50\n",
        "                        if sent != target_sent and sent not in used_targets:\n",
        "                            input_context = self._analyze_sentence_context(sent)\n",
        "\n",
        "                            # Calculate contextual compatibility\n",
        "                            compatibility = self._calculate_context_compatibility(input_context, target_context)\n",
        "\n",
        "                            if compatibility > best_score and compatibility > 0.2:\n",
        "                                best_score = compatibility\n",
        "                                best_input = sent\n",
        "\n",
        "                    if best_input and best_score > 0.2:\n",
        "                        sentence_pairs.append({\n",
        "                            'input': best_input,\n",
        "                            'target': target_sent,\n",
        "                            'probability': float(best_score + 0.1),\n",
        "                            'context_compatibility': float(best_score),\n",
        "                            'pair_type': 'contextual_diversity'\n",
        "                        })\n",
        "                        similarity_scores.append(best_score + 0.1)\n",
        "                        used_targets.add(target_sent)\n",
        "\n",
        "        print(f\"âœ… Added contextual diversity pairs, total: {len(sentence_pairs)}\")\n",
        "\n",
        "    def create_contextual_pairs(self):\n",
        "        \"\"\"\n",
        "        Enhanced method to create contextual sentence pairs with unique high-probability mapping\n",
        "        \"\"\"\n",
        "        print(\"ðŸ”„ Creating enhanced contextual representation with unique probability-based pairing...\")\n",
        "\n",
        "        # Step 1: Create masked contexts for all sentences\n",
        "        all_contexts = []\n",
        "        original_mapping = []\n",
        "        unique_originals = []\n",
        "\n",
        "        for i, sentence in enumerate(self.sentences[:2000]):  # Limit for efficiency\n",
        "            masked_versions = self.create_masked_contexts(sentence)\n",
        "            for masked_sent in masked_versions:\n",
        "                all_contexts.append(masked_sent)\n",
        "                original_mapping.append((i, sentence))\n",
        "\n",
        "            # Track unique original sentences for pairing\n",
        "            if sentence not in unique_originals:\n",
        "                unique_originals.append(sentence)\n",
        "\n",
        "        print(f\"ðŸ“Š Created {len(all_contexts)} masked contexts from {len(self.sentences[:2000])} sentences\")\n",
        "        print(f\"ðŸŽ¯ Found {len(unique_originals)} unique sentences for probability pairing\")\n",
        "\n",
        "        # Step 2: Calculate embeddings for original sentences (not masked)\n",
        "        print(\"ðŸ“ˆ Calculating embeddings for unique sentence probability distribution...\")\n",
        "        embedding_result = self.calculate_sentence_embeddings(unique_originals)\n",
        "\n",
        "        if embedding_result[0] is not None:\n",
        "            # Unpack all 4 returned values\n",
        "            embeddings, vectorizer, contextual_features, sentence_features = embedding_result\n",
        "        else:\n",
        "            # Handle fallback case\n",
        "            embeddings, vectorizer, contextual_features, sentence_features = None, None, None, embedding_result[3]\n",
        "\n",
        "        # Step 3: Create unique probability-based pairs from original sentences\n",
        "        print(\"ðŸŽ¯ Creating unique high-probability sentence pairs...\")\n",
        "        unique_contextual_pairs, unique_prob_scores = self.calculate_probability_distribution(\n",
        "            unique_originals, embeddings, contextual_features, sentence_features\n",
        "        )\n",
        "\n",
        "        # Step 4: Create masked context pairs (input-output for reconstruction)\n",
        "        print(\"ðŸŽ­ Creating masked reconstruction pairs...\")\n",
        "        reconstruction_pairs = []\n",
        "        for masked_context, (orig_idx, original_sent) in zip(all_contexts, original_mapping):\n",
        "            if '[MASK]' in masked_context:\n",
        "                reconstruction_pairs.append({\n",
        "                    'input': masked_context,\n",
        "                    'target': original_sent,\n",
        "                    'probability': 1.0,  # High probability for reconstruction\n",
        "                    'pair_type': 'reconstruction',\n",
        "                    'context_type': 'masked_reconstruction'\n",
        "                })\n",
        "\n",
        "        # Step 5: Enhanced contextual pairs - combine masked inputs with high-probability targets\n",
        "        print(\"ðŸš€ Creating enhanced contextual pairs with probability mapping...\")\n",
        "        enhanced_contextual_pairs = []\n",
        "\n",
        "        # Map masked contexts to high-probability targets from unique pairs\n",
        "        for masked_context, (orig_idx, original_sent) in zip(all_contexts, original_mapping):\n",
        "            # Find high-probability targets for this original sentence\n",
        "            related_pairs = [pair for pair in unique_contextual_pairs\n",
        "                           if pair['input'] == original_sent and pair['probability'] > 0.3]\n",
        "\n",
        "            if related_pairs:\n",
        "                # Use the highest probability target\n",
        "                best_pair = max(related_pairs, key=lambda x: x['probability'])\n",
        "                enhanced_contextual_pairs.append({\n",
        "                    'input': masked_context,  # Masked version as input\n",
        "                    'target': best_pair['target'],  # High-probability sentence as target\n",
        "                    'probability': best_pair['probability'],\n",
        "                    'pair_type': 'enhanced_contextual',\n",
        "                    'context_type': 'masked_to_probable'\n",
        "                })\n",
        "\n",
        "        # Step 6: Add direct high-probability pairs\n",
        "        for pair in unique_contextual_pairs:\n",
        "            if pair['probability'] > 0.25:  # High-quality threshold\n",
        "                enhanced_contextual_pairs.append({\n",
        "                    'input': pair['input'],\n",
        "                    'target': pair['target'],\n",
        "                    'probability': pair['probability'],\n",
        "                    'pair_type': pair['pair_type'],\n",
        "                    'context_type': 'direct_probable'\n",
        "                })\n",
        "\n",
        "        # Combine all pairs\n",
        "        all_pairs = reconstruction_pairs + enhanced_contextual_pairs\n",
        "        all_prob_scores = [1.0] * len(reconstruction_pairs) + unique_prob_scores\n",
        "\n",
        "        # Remove duplicates while preserving highest probability pairs\n",
        "        unique_pairs = {}\n",
        "        for pair in all_pairs:\n",
        "            key = (pair['input'], pair['target'])\n",
        "            if key not in unique_pairs or pair['probability'] > unique_pairs[key]['probability']:\n",
        "                unique_pairs[key] = pair\n",
        "\n",
        "        final_pairs = list(unique_pairs.values())\n",
        "\n",
        "        print(f\"âœ… Created {len(final_pairs)} unique high-quality pairs:\")\n",
        "        print(f\"   ðŸŽ­ Reconstruction pairs: {len(reconstruction_pairs)}\")\n",
        "        print(f\"   ðŸ”— Enhanced contextual pairs: {len(enhanced_contextual_pairs)}\")\n",
        "        print(f\"   ðŸŽ¯ Unique probability-based pairs: {len(unique_contextual_pairs)}\")\n",
        "        print(f\"   ðŸ“Š Final deduplicated pairs: {len(final_pairs)}\")\n",
        "\n",
        "        # Quality analysis\n",
        "        high_prob_pairs = [p for p in final_pairs if p['probability'] > 0.5]\n",
        "        medium_prob_pairs = [p for p in final_pairs if 0.3 <= p['probability'] <= 0.5]\n",
        "\n",
        "        print(f\"ðŸ“ˆ Quality distribution:\")\n",
        "        print(f\"   ðŸ† High probability (>0.5): {len(high_prob_pairs)}\")\n",
        "        print(f\"   ðŸ“ˆ Medium probability (0.3-0.5): {len(medium_prob_pairs)}\")\n",
        "        print(f\"   ðŸ“Š Average probability: {np.mean([p['probability'] for p in final_pairs]):.3f}\")\n",
        "\n",
        "        return final_pairs, all_prob_scores\n",
        "\n",
        "# Initialize context representation maker\n",
        "print(\"ðŸš€ Starting enhanced context representation creation...\")\n",
        "\n",
        "# Check if required variables exist from previous cells\n",
        "if 'urdu_sentences' not in locals():\n",
        "    print(\"âŒ Error: urdu_sentences not found. Please run previous cells first.\")\n",
        "elif 'tokenizer' not in locals():\n",
        "    print(\"âŒ Error: tokenizer not found. Please run previous cells first.\")\n",
        "elif 'device' not in locals():\n",
        "    print(\"âŒ Error: device not found. Please run previous cells first.\")\n",
        "else:\n",
        "    # Create enhanced contextual pairs\n",
        "    context_maker = ContextRepresentationMaker(urdu_sentences, tokenizer, device)\n",
        "    enhanced_pairs, probability_scores = context_maker.create_contextual_pairs()\n",
        "\n",
        "    print(f\"\\nðŸ“ˆ Probability Distribution Statistics:\")\n",
        "    if probability_scores:\n",
        "        print(f\"   ðŸ“Š Mean probability: {np.mean(probability_scores):.3f}\")\n",
        "        print(f\"   ðŸ“Š Std probability: {np.std(probability_scores):.3f}\")\n",
        "        print(f\"   ðŸ“Š Max probability: {np.max(probability_scores):.3f}\")\n",
        "        print(f\"   ðŸ“Š Min probability: {np.min(probability_scores):.3f}\")\n",
        "\n",
        "    # Show examples of created pairs\n",
        "    print(f\"\\nðŸ“ Example Enhanced Pairs:\")\n",
        "    for i, pair in enumerate(enhanced_pairs[:5]):\n",
        "        print(f\"\\n{i+1}. Type: {pair['pair_type']} | Prob: {pair['probability']:.3f}\")\n",
        "        print(f\"   ðŸ”¤ Input:  {pair['input'][:60]}...\")\n",
        "        print(f\"   ðŸŽ¯ Target: {pair['target'][:60]}...\")\n",
        "\n",
        "    print(f\"\\nâœ… Enhanced context representation completed!\")\n",
        "    print(f\"ðŸ“Š Total enhanced pairs: {len(enhanced_pairs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "54a0158a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54a0158a",
        "outputId": "892a3a3f-5e96-4b6d-d9f7-2f9263e2e386"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ’¾ Saving enhanced contextual data to files...\n",
            "ðŸ“Š Enhanced Data Quality Distribution:\n",
            "   ðŸŽ­ Reconstruction pairs: 7157\n",
            "   ðŸš€ Enhanced contextual pairs: 139\n",
            "   ðŸŽ¯ Direct probability pairs: 0\n",
            "   ðŸ† Ultra-high quality (prob â‰¥ 0.5): 7199\n",
            "   ðŸ“ˆ High quality (0.3-0.5): 187\n",
            "   ðŸ“Š Medium quality (0.1-0.3): 48\n",
            "\n",
            "ðŸŽ¯ Context Type Distribution:\n",
            "   ðŸŽ­ Masked â†’ Original: 7157\n",
            "   ðŸ”— Masked â†’ High-Probability: 139\n",
            "   ðŸ“Š Direct High-Probability: 138\n",
            "âœ… Saved enhanced_all_pairs: 7434 pairs\n",
            "âœ… Saved reconstruction_pairs: 7157 pairs\n",
            "âœ… Saved enhanced_contextual_pairs: 139 pairs\n",
            "âœ… Saved direct_probability_pairs: 0 pairs\n",
            "âœ… Saved ultra_high_quality_pairs: 7199 pairs\n",
            "âœ… Saved high_quality_pairs: 187 pairs\n",
            "âœ… Saved medium_quality_pairs: 48 pairs\n",
            "âœ… Saved masked_reconstruction_pairs: 7157 pairs\n",
            "âœ… Saved masked_to_probable_pairs: 139 pairs\n",
            "âœ… Saved direct_probable_pairs: 138 pairs\n",
            "\n",
            "ðŸ“¦ Enhanced Weighted Training Data: 65166 examples\n",
            "ðŸ“Š Weight Distribution:\n",
            "   ultra_high: 35953 examples\n",
            "   reconstruction: 28628 examples\n",
            "   enhanced_contextual: 417 examples\n",
            "   medium_quality: 48 examples\n",
            "   high_quality: 120 examples\n",
            "\n",
            "âœ… All enhanced contextual data saved!\n",
            "ðŸ“ Files saved to /content/urdu_files/:\n",
            "   ðŸ“Š enhanced_all_pairs.pkl/csv (7434 pairs)\n",
            "   ðŸŽ­ reconstruction_pairs.pkl/csv (7157 pairs)\n",
            "   ðŸ”— enhanced_contextual_pairs.pkl/csv (139 pairs)\n",
            "   ðŸŽ¯ direct_probability_pairs.pkl/csv (0 pairs)\n",
            "   ðŸ† ultra_high_quality_pairs.pkl/csv (7199 pairs)\n",
            "   ðŸ“ˆ high_quality_pairs.pkl/csv (187 pairs)\n",
            "   ðŸ“Š medium_quality_pairs.pkl/csv (48 pairs)\n",
            "   âš–ï¸ weighted_training_data.pkl/csv (65166 examples)\n",
            "   ðŸ“‹ enhanced_dataset_metadata.pkl/json\n",
            "\n",
            "ðŸŽ¯ Enhanced Context Representation Summary:\n",
            "   ðŸ§  Masking strategies: Random, Important words, Sequential\n",
            "   ðŸ“Š Probability-based pairing using TF-IDF cosine similarity\n",
            "   ðŸŽ­ Reconstruction pairs for context learning\n",
            "   ðŸ”— Similarity pairs for conversation flow\n",
            "   âš–ï¸ Weighted training data for balanced learning\n"
          ]
        }
      ],
      "source": [
        "# ðŸ’¾ SAVE ENHANCED CONTEXTUAL DATA TO FILES\n",
        "print(\"ðŸ’¾ Saving enhanced contextual data to files...\")\n",
        "\n",
        "# Check dependencies from previous cells\n",
        "if 'enhanced_pairs' not in locals():\n",
        "    print(\"âŒ Error: enhanced_pairs not found. Please run the previous cell first.\")\n",
        "    enhanced_pairs = []\n",
        "if 'probability_scores' not in locals():\n",
        "    print(\"âŒ Error: probability_scores not found. Please run the previous cell first.\")\n",
        "    probability_scores = []\n",
        "\n",
        "if enhanced_pairs:\n",
        "    # Enhanced categorization of pairs by type and context\n",
        "    reconstruction_pairs = [pair for pair in enhanced_pairs if pair['pair_type'] == 'reconstruction']\n",
        "\n",
        "    # Enhanced contextual pairs (masked to high-probability targets)\n",
        "    enhanced_contextual_pairs = [pair for pair in enhanced_pairs if pair['pair_type'] == 'enhanced_contextual']\n",
        "\n",
        "    # Direct probability-based pairs (unique sentence mappings)\n",
        "    direct_probability_pairs = [pair for pair in enhanced_pairs if\n",
        "                              pair['pair_type'] in ['similarity_based', 'enhanced_word_overlap', 'diversity_pair']]\n",
        "\n",
        "    # Quality-based categorization\n",
        "    ultra_high_quality_pairs = [pair for pair in enhanced_pairs if pair['probability'] >= 0.5]\n",
        "    high_quality_pairs = [pair for pair in enhanced_pairs if 0.3 <= pair['probability'] < 0.5]\n",
        "    medium_quality_pairs = [pair for pair in enhanced_pairs if 0.1 <= pair['probability'] < 0.3]\n",
        "\n",
        "    # Context-type categorization (new feature)\n",
        "    masked_reconstruction = [pair for pair in enhanced_pairs if\n",
        "                           pair.get('context_type') == 'masked_reconstruction']\n",
        "    masked_to_probable = [pair for pair in enhanced_pairs if\n",
        "                         pair.get('context_type') == 'masked_to_probable']\n",
        "    direct_probable = [pair for pair in enhanced_pairs if\n",
        "                      pair.get('context_type') == 'direct_probable']\n",
        "\n",
        "    print(f\"ðŸ“Š Enhanced Data Quality Distribution:\")\n",
        "    print(f\"   ðŸŽ­ Reconstruction pairs: {len(reconstruction_pairs)}\")\n",
        "    print(f\"   ðŸš€ Enhanced contextual pairs: {len(enhanced_contextual_pairs)}\")\n",
        "    print(f\"   ðŸŽ¯ Direct probability pairs: {len(direct_probability_pairs)}\")\n",
        "    print(f\"   ðŸ† Ultra-high quality (prob â‰¥ 0.5): {len(ultra_high_quality_pairs)}\")\n",
        "    print(f\"   ðŸ“ˆ High quality (0.3-0.5): {len(high_quality_pairs)}\")\n",
        "    print(f\"   ðŸ“Š Medium quality (0.1-0.3): {len(medium_quality_pairs)}\")\n",
        "\n",
        "    print(f\"\\nðŸŽ¯ Context Type Distribution:\")\n",
        "    print(f\"   ðŸŽ­ Masked â†’ Original: {len(masked_reconstruction)}\")\n",
        "    print(f\"   ðŸ”— Masked â†’ High-Probability: {len(masked_to_probable)}\")\n",
        "    print(f\"   ðŸ“Š Direct High-Probability: {len(direct_probable)}\")\n",
        "\n",
        "    # Create comprehensive training datasets with enhanced categorization\n",
        "    training_datasets = {\n",
        "        'enhanced_all_pairs': enhanced_pairs,\n",
        "        'reconstruction_pairs': reconstruction_pairs,\n",
        "        'enhanced_contextual_pairs': enhanced_contextual_pairs,\n",
        "        'direct_probability_pairs': direct_probability_pairs,\n",
        "        'ultra_high_quality_pairs': ultra_high_quality_pairs,\n",
        "        'high_quality_pairs': high_quality_pairs,\n",
        "        'medium_quality_pairs': medium_quality_pairs,\n",
        "        'masked_reconstruction_pairs': masked_reconstruction,\n",
        "        'masked_to_probable_pairs': masked_to_probable,\n",
        "        'direct_probable_pairs': direct_probable\n",
        "    }\n",
        "\n",
        "    # Save each dataset type\n",
        "    for dataset_name, dataset in training_datasets.items():\n",
        "        # Save as pickle\n",
        "        with open(f'/content/urdu_files/{dataset_name}.pkl', 'wb') as f:\n",
        "            pickle.dump(dataset, f)\n",
        "\n",
        "        # Save as CSV for human inspection\n",
        "        df = pd.DataFrame(dataset)\n",
        "        df.to_csv(f'/content/urdu_files/{dataset_name}.csv', index=False, encoding='utf-8')\n",
        "\n",
        "        print(f\"âœ… Saved {dataset_name}: {len(dataset)} pairs\")\n",
        "\n",
        "    # Create enhanced weighted training data with sophisticated probability weighting\n",
        "    weighted_training_data = []\n",
        "\n",
        "    # 1. Ultra-high quality pairs (5x weight) - Best unique mappings\n",
        "    for pair in ultra_high_quality_pairs:\n",
        "        weight_multiplier = 5 if pair['probability'] >= 0.7 else 4\n",
        "        weighted_training_data.extend([{\n",
        "            'input': pair['input'],\n",
        "            'target': pair['target'],\n",
        "            'weight': pair['probability'],\n",
        "            'type': pair['pair_type'],\n",
        "            'context_type': pair.get('context_type', 'unknown'),\n",
        "            'quality_tier': 'ultra_high'\n",
        "        }] * weight_multiplier)\n",
        "\n",
        "    # 2. Reconstruction pairs (4x weight) - Essential for context learning\n",
        "    for pair in reconstruction_pairs:\n",
        "        weighted_training_data.extend([{\n",
        "            'input': pair['input'],\n",
        "            'target': pair['target'],\n",
        "            'weight': pair['probability'],\n",
        "            'type': pair['pair_type'],\n",
        "            'context_type': pair.get('context_type', 'unknown'),\n",
        "            'quality_tier': 'reconstruction'\n",
        "        }] * 4)\n",
        "\n",
        "    # 3. Enhanced contextual pairs (3x weight) - Masked to high-probability targets\n",
        "    for pair in enhanced_contextual_pairs:\n",
        "        if pair['probability'] >= 0.3:\n",
        "            weighted_training_data.extend([{\n",
        "                'input': pair['input'],\n",
        "                'target': pair['target'],\n",
        "                'weight': pair['probability'],\n",
        "                'type': pair['pair_type'],\n",
        "                'context_type': pair.get('context_type', 'unknown'),\n",
        "                'quality_tier': 'enhanced_contextual'\n",
        "            }] * 3)\n",
        "\n",
        "    # 4. High-quality direct probability pairs (2x weight)\n",
        "    for pair in high_quality_pairs:\n",
        "        if pair['pair_type'] not in ['reconstruction', 'enhanced_contextual']:\n",
        "            weighted_training_data.extend([{\n",
        "                'input': pair['input'],\n",
        "                'target': pair['target'],\n",
        "                'weight': pair['probability'],\n",
        "                'type': pair['pair_type'],\n",
        "                'context_type': pair.get('context_type', 'unknown'),\n",
        "                'quality_tier': 'high_quality'\n",
        "            }] * 2)\n",
        "\n",
        "    # 5. Medium-quality pairs (1x weight) - For diversity\n",
        "    for pair in medium_quality_pairs:\n",
        "        if pair['probability'] >= 0.15:  # Only better medium-quality pairs\n",
        "            weighted_training_data.append({\n",
        "                'input': pair['input'],\n",
        "                'target': pair['target'],\n",
        "                'weight': pair['probability'],\n",
        "                'type': pair['pair_type'],\n",
        "                'context_type': pair.get('context_type', 'unknown'),\n",
        "                'quality_tier': 'medium_quality'\n",
        "            })\n",
        "\n",
        "    # Shuffle weighted training data while preserving quality distribution\n",
        "    np.random.shuffle(weighted_training_data)\n",
        "\n",
        "    print(f\"\\nðŸ“¦ Enhanced Weighted Training Data: {len(weighted_training_data)} examples\")\n",
        "\n",
        "    # Analyze weight distribution\n",
        "    weight_tiers = {}\n",
        "    for item in weighted_training_data:\n",
        "        tier = item['quality_tier']\n",
        "        weight_tiers[tier] = weight_tiers.get(tier, 0) + 1\n",
        "\n",
        "    print(f\"ðŸ“Š Weight Distribution:\")\n",
        "    for tier, count in weight_tiers.items():\n",
        "        print(f\"   {tier}: {count} examples\")\n",
        "\n",
        "    # Save weighted training data\n",
        "    with open('/content/urdu_files/weighted_training_data.pkl', 'wb') as f:\n",
        "        pickle.dump(weighted_training_data, f)\n",
        "\n",
        "    pd.DataFrame(weighted_training_data).to_csv('/content/urdu_files/weighted_training_data.csv', index=False, encoding='utf-8')\n",
        "\n",
        "    # Create enhanced metadata about the dataset\n",
        "    dataset_metadata = {\n",
        "        'total_pairs': len(enhanced_pairs),\n",
        "        'reconstruction_pairs': len(reconstruction_pairs),\n",
        "        'enhanced_contextual_pairs': len(enhanced_contextual_pairs),\n",
        "        'direct_probability_pairs': len(direct_probability_pairs),\n",
        "        'ultra_high_quality_pairs': len(ultra_high_quality_pairs),\n",
        "        'high_quality_pairs': len(high_quality_pairs),\n",
        "        'medium_quality_pairs': len(medium_quality_pairs),\n",
        "        'weighted_training_size': len(weighted_training_data),\n",
        "        'unique_pairing_method': 'enhanced_probability_distribution_with_uniqueness',\n",
        "        'context_types': {\n",
        "            'masked_reconstruction': len(masked_reconstruction),\n",
        "            'masked_to_probable': len(masked_to_probable),\n",
        "            'direct_probable': len(direct_probable)\n",
        "        },\n",
        "        'probability_stats': {\n",
        "            'mean': float(np.mean(probability_scores)) if probability_scores else 0,\n",
        "            'std': float(np.std(probability_scores)) if probability_scores else 0,\n",
        "            'max': float(np.max(probability_scores)) if probability_scores else 0,\n",
        "            'min': float(np.min(probability_scores)) if probability_scores else 0\n",
        "        },\n",
        "        'enhanced_features': {\n",
        "            'unique_sentence_pairing': True,\n",
        "            'probability_based_mapping': True,\n",
        "            'deduplication_with_highest_prob': True,\n",
        "            'quality_tier_weighting': True,\n",
        "            'context_type_classification': True\n",
        "        },\n",
        "        'masking_strategies': ['random', 'important_words', 'sequential'],\n",
        "        'context_creation_method': 'enhanced_masking_with_unique_probability_distribution',\n",
        "        'similarity_method': 'enhanced_tfidf_cosine_with_diversity_pairs'\n",
        "    }\n",
        "\n",
        "    # Save metadata\n",
        "    with open('/content/urdu_files/enhanced_dataset_metadata.pkl', 'wb') as f:\n",
        "        pickle.dump(dataset_metadata, f)\n",
        "\n",
        "    with open('/content/urdu_files/enhanced_dataset_metadata.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(dataset_metadata, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\\nâœ… All enhanced contextual data saved!\")\n",
        "    print(f\"ðŸ“ Files saved to /content/urdu_files/:\")\n",
        "    print(f\"   ðŸ“Š enhanced_all_pairs.pkl/csv ({len(enhanced_pairs)} pairs)\")\n",
        "    print(f\"   ðŸŽ­ reconstruction_pairs.pkl/csv ({len(reconstruction_pairs)} pairs)\")\n",
        "    print(f\"   ðŸ”— enhanced_contextual_pairs.pkl/csv ({len(enhanced_contextual_pairs)} pairs)\")\n",
        "    print(f\"   ðŸŽ¯ direct_probability_pairs.pkl/csv ({len(direct_probability_pairs)} pairs)\")\n",
        "    print(f\"   ðŸ† ultra_high_quality_pairs.pkl/csv ({len(ultra_high_quality_pairs)} pairs)\")\n",
        "    print(f\"   ðŸ“ˆ high_quality_pairs.pkl/csv ({len(high_quality_pairs)} pairs)\")\n",
        "    print(f\"   ðŸ“Š medium_quality_pairs.pkl/csv ({len(medium_quality_pairs)} pairs)\")\n",
        "    print(f\"   âš–ï¸ weighted_training_data.pkl/csv ({len(weighted_training_data)} examples)\")\n",
        "    print(f\"   ðŸ“‹ enhanced_dataset_metadata.pkl/json\")\n",
        "\n",
        "    print(f\"\\nðŸŽ¯ Enhanced Context Representation Summary:\")\n",
        "    print(f\"   ðŸ§  Masking strategies: Random, Important words, Sequential\")\n",
        "    print(f\"   ðŸ“Š Probability-based pairing using TF-IDF cosine similarity\")\n",
        "    print(f\"   ðŸŽ­ Reconstruction pairs for context learning\")\n",
        "    print(f\"   ðŸ”— Similarity pairs for conversation flow\")\n",
        "    print(f\"   âš–ï¸ Weighted training data for balanced learning\")\n",
        "else:\n",
        "    print(\"âš ï¸ No enhanced pairs found. Please run previous cells to create contextual data.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a20b2a67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a20b2a67",
        "outputId": "e588fb59-5703-4ab6-fcdc-8f6f43e7658f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ Creating enhanced dataset class for contextual training...\n",
            "ðŸ“¦ Creating enhanced datasets...\n",
            "âœ… Enhanced datasets created:\n",
            "   ðŸš‚ Training: 65166 examples, 2716 batches\n",
            "   ðŸ“Š Validation: 37 examples, 2 batches\n",
            "   ðŸ§ª Test: 37 examples, 2 batches\n",
            "ðŸ’¾ Saved enhanced_train_dataset.pkl: 65166 examples\n",
            "ðŸ’¾ Saved enhanced_val_dataset.pkl: 37 examples\n",
            "ðŸ’¾ Saved enhanced_test_dataset.pkl: 37 examples\n",
            "\n",
            "ðŸŽ¯ Enhanced dataset features:\n",
            "   ðŸ§  Context-aware masking strategies\n",
            "   ðŸ“Š Probability-weighted sampling\n",
            "   ðŸŽ­ Reconstruction and similarity pairs\n",
            "   ðŸ’¡ Enhanced attention masks\n",
            "   âš–ï¸ Type-specific loss masking\n"
          ]
        }
      ],
      "source": [
        "# ðŸŽ¯ ENHANCED DATASET CLASS FOR CONTEXTUAL TRAINING\n",
        "print(\"ðŸŽ¯ Creating enhanced dataset class for contextual training...\")\n",
        "\n",
        "# Check dependencies from previous cells\n",
        "required_vars = ['weighted_training_data', 'high_quality_pairs', 'tokenizer', 'PAD_ID', 'BOS_ID', 'EOS_ID', 'UNK_ID']\n",
        "missing_vars = [var for var in required_vars if var not in locals()]\n",
        "\n",
        "if missing_vars:\n",
        "    print(f\"âŒ Error: Missing required variables: {missing_vars}\")\n",
        "    print(\"Please run all previous cells in order.\")\n",
        "else:\n",
        "    class EnhancedUrduDataset(Dataset):\n",
        "        \"\"\"\n",
        "        Enhanced dataset class that uses the probability-weighted contextual pairs\n",
        "        for better chatbot training with context representation\n",
        "        \"\"\"\n",
        "\n",
        "        def __init__(self, enhanced_data, tokenizer, max_len=128, use_weights=True):\n",
        "            self.data = enhanced_data\n",
        "            self.tokenizer = tokenizer\n",
        "            self.max_len = max_len\n",
        "            self.use_weights = use_weights\n",
        "\n",
        "            # Create sample weights for weighted sampling\n",
        "            if use_weights and len(enhanced_data) > 0 and 'weight' in enhanced_data[0]:\n",
        "                self.weights = [item['weight'] for item in enhanced_data]\n",
        "                # Normalize weights\n",
        "                total_weight = sum(self.weights)\n",
        "                self.weights = [w / total_weight for w in self.weights] if total_weight > 0 else self.weights\n",
        "            else:\n",
        "                self.weights = None\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.data)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            item = self.data[idx]\n",
        "\n",
        "            # Tokenize input and target\n",
        "            src_ids = self.tokenizer.encode(item['input'], add_bos=True, add_eos=True)[:self.max_len]\n",
        "            tgt_ids = self.tokenizer.encode(item['target'], add_bos=True, add_eos=True)[:self.max_len]\n",
        "\n",
        "            # Create attention mask for better context understanding\n",
        "            src_attention_mask = torch.ones(len(src_ids), dtype=torch.bool)\n",
        "            tgt_attention_mask = torch.ones(len(tgt_ids), dtype=torch.bool)\n",
        "\n",
        "            # Create loss mask based on pair type\n",
        "            loss_mask = torch.ones(len(tgt_ids), dtype=torch.bool)\n",
        "\n",
        "            # For reconstruction pairs, focus on masked positions\n",
        "            if item.get('type') == 'reconstruction' and '[MASK]' in item['input']:\n",
        "                # Enhanced loss mask for reconstruction\n",
        "                input_tokens = self.tokenizer.encode(item['input'], add_bos=False, add_eos=False)\n",
        "                target_tokens = self.tokenizer.encode(item['target'], add_bos=False, add_eos=False)\n",
        "\n",
        "                loss_mask = torch.zeros(len(tgt_ids), dtype=torch.bool)\n",
        "                # Focus on positions where input has [MASK]\n",
        "                mask_token_id = self.tokenizer.encode('[MASK]', add_bos=False, add_eos=False)\n",
        "                if mask_token_id:\n",
        "                    mask_token_id = mask_token_id[0]\n",
        "\n",
        "                    for i, input_token in enumerate(input_tokens):\n",
        "                        if i < len(tgt_ids) - 1:\n",
        "                            if input_token == mask_token_id or (i < len(target_tokens) and input_token != target_tokens[i]):\n",
        "                                loss_mask[i + 1] = True  # +1 for BOS token\n",
        "            else:\n",
        "                # For similarity pairs, use full loss\n",
        "                loss_mask[1:] = True  # Skip BOS token\n",
        "\n",
        "            return {\n",
        "                'src_ids': torch.tensor(src_ids, dtype=torch.long),\n",
        "                'tgt_ids': torch.tensor(tgt_ids, dtype=torch.long),\n",
        "                'src_attention_mask': src_attention_mask,\n",
        "                'tgt_attention_mask': tgt_attention_mask,\n",
        "                'loss_mask': loss_mask,\n",
        "                'weight': torch.tensor(item.get('weight', 1.0), dtype=torch.float),\n",
        "                'pair_type': item.get('type', 'unknown')\n",
        "            }\n",
        "\n",
        "    def enhanced_collate_fn(batch):\n",
        "        \"\"\"Enhanced collate function with attention masks and weights\"\"\"\n",
        "        src_ids = [item['src_ids'] for item in batch]\n",
        "        tgt_ids = [item['tgt_ids'] for item in batch]\n",
        "        src_masks = [item['src_attention_mask'] for item in batch]\n",
        "        tgt_masks = [item['tgt_attention_mask'] for item in batch]\n",
        "        loss_masks = [item['loss_mask'] for item in batch]\n",
        "        weights = [item['weight'] for item in batch]\n",
        "        pair_types = [item['pair_type'] for item in batch]\n",
        "\n",
        "        # Find max length\n",
        "        max_src_len = max(len(ids) for ids in src_ids)\n",
        "        max_tgt_len = max(len(ids) for ids in tgt_ids)\n",
        "        max_len = max(max_src_len, max_tgt_len)\n",
        "\n",
        "        # Pad sequences\n",
        "        src_batch = torch.zeros(len(batch), max_len, dtype=torch.long)\n",
        "        tgt_batch = torch.zeros(len(batch), max_len, dtype=torch.long)\n",
        "        src_mask_batch = torch.zeros(len(batch), max_len, dtype=torch.bool)\n",
        "        tgt_mask_batch = torch.zeros(len(batch), max_len, dtype=torch.bool)\n",
        "        loss_mask_batch = torch.zeros(len(batch), max_len, dtype=torch.bool)\n",
        "\n",
        "        for i in range(len(batch)):\n",
        "            src_len, tgt_len = len(src_ids[i]), len(tgt_ids[i])\n",
        "\n",
        "            src_batch[i, :src_len] = src_ids[i]\n",
        "            tgt_batch[i, :tgt_len] = tgt_ids[i]\n",
        "            src_mask_batch[i, :src_len] = src_masks[i]\n",
        "            tgt_mask_batch[i, :tgt_len] = tgt_masks[i]\n",
        "            loss_mask_batch[i, :len(loss_masks[i])] = loss_masks[i]\n",
        "\n",
        "        return {\n",
        "            'src': src_batch,\n",
        "            'tgt': tgt_batch,\n",
        "            'src_mask': src_mask_batch,\n",
        "            'tgt_mask': tgt_mask_batch,\n",
        "            'loss_mask': loss_mask_batch,\n",
        "            'weights': torch.tensor(weights, dtype=torch.float),\n",
        "            'pair_types': pair_types\n",
        "        }\n",
        "\n",
        "    # Create enhanced datasets from the saved contextual data\n",
        "    print(\"ðŸ“¦ Creating enhanced datasets...\")\n",
        "\n",
        "    # Use the weighted training data for best results\n",
        "    enhanced_train_dataset = EnhancedUrduDataset(weighted_training_data, tokenizer, use_weights=True)\n",
        "\n",
        "    # Create validation and test sets from high-quality pairs\n",
        "    high_quality_size = len(high_quality_pairs)\n",
        "    val_size = int(high_quality_size * 0.2)\n",
        "    test_size = int(high_quality_size * 0.2)\n",
        "\n",
        "    enhanced_val_data = high_quality_pairs[:val_size] if high_quality_size > 0 else []\n",
        "    enhanced_test_data = high_quality_pairs[val_size:val_size + test_size] if high_quality_size > val_size else []\n",
        "\n",
        "    enhanced_val_dataset = EnhancedUrduDataset(enhanced_val_data, tokenizer, use_weights=False)\n",
        "    enhanced_test_dataset = EnhancedUrduDataset(enhanced_test_data, tokenizer, use_weights=False)\n",
        "\n",
        "    # Create data loaders\n",
        "    ENHANCED_BATCH_SIZE = 24  # Slightly smaller for memory efficiency with enhanced features\n",
        "\n",
        "    enhanced_train_loader = DataLoader(\n",
        "        enhanced_train_dataset,\n",
        "        batch_size=ENHANCED_BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=enhanced_collate_fn,\n",
        "        pin_memory=torch.cuda.is_available()\n",
        "    )\n",
        "\n",
        "    enhanced_val_loader = DataLoader(\n",
        "        enhanced_val_dataset,\n",
        "        batch_size=ENHANCED_BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        collate_fn=enhanced_collate_fn,\n",
        "        pin_memory=torch.cuda.is_available()\n",
        "    ) if enhanced_val_data else None\n",
        "\n",
        "    enhanced_test_loader = DataLoader(\n",
        "        enhanced_test_dataset,\n",
        "        batch_size=ENHANCED_BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        collate_fn=enhanced_collate_fn,\n",
        "        pin_memory=torch.cuda.is_available()\n",
        "    ) if enhanced_test_data else None\n",
        "\n",
        "    print(f\"âœ… Enhanced datasets created:\")\n",
        "    print(f\"   ðŸš‚ Training: {len(enhanced_train_dataset)} examples, {len(enhanced_train_loader)} batches\")\n",
        "    print(f\"   ðŸ“Š Validation: {len(enhanced_val_dataset)} examples, {len(enhanced_val_loader) if enhanced_val_loader else 0} batches\")\n",
        "    print(f\"   ðŸ§ª Test: {len(enhanced_test_dataset)} examples, {len(enhanced_test_loader) if enhanced_test_loader else 0} batches\")\n",
        "\n",
        "    # Save enhanced datasets\n",
        "    enhanced_datasets = {\n",
        "        'train': weighted_training_data,\n",
        "        'val': enhanced_val_data,\n",
        "        'test': enhanced_test_data\n",
        "    }\n",
        "\n",
        "    for split_name, split_data in enhanced_datasets.items():\n",
        "        with open(f'/content/urdu_files/enhanced_{split_name}_dataset.pkl', 'wb') as f:\n",
        "            pickle.dump(split_data, f)\n",
        "        print(f\"ðŸ’¾ Saved enhanced_{split_name}_dataset.pkl: {len(split_data)} examples\")\n",
        "\n",
        "    print(f\"\\nðŸŽ¯ Enhanced dataset features:\")\n",
        "    print(f\"   ðŸ§  Context-aware masking strategies\")\n",
        "    print(f\"   ðŸ“Š Probability-weighted sampling\")\n",
        "    print(f\"   ðŸŽ­ Reconstruction and similarity pairs\")\n",
        "    print(f\"   ðŸ’¡ Enhanced attention masks\")\n",
        "    print(f\"   âš–ï¸ Type-specific loss masking\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3bb313aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "970e63a3d94349e08cece97a4cc7ea92",
            "daa07920c0d74b1fb97f6451a432636d",
            "a3bb3589507448d88e998009f134290a",
            "0ac587b5deba483d9071657634a05fb3",
            "0cd35ced22a84a05a0717dabd5fdf92d",
            "6fe4d71b58e1432cb52072c5705a5a38",
            "137b8da439344526bc38008de8f9be13",
            "448cb4eecdd54fa990940d57bd6aa052",
            "faf3b1266afd45498cd8125261f01336",
            "e7bacea7b3354360a976ccc9cea70976",
            "7ec6a05ce6aa42dc9c555374ce1f8b3d",
            "e7c069c7066446a7917570721aa1df46",
            "d8bdffb2b37c4600921ef4a4f27304d4",
            "a67682dc3e79454d9c19bf576628cade",
            "c5bd1f6e00064a62bbc87c617d45d82b",
            "95008f9b46044d23ad7753367297e958",
            "412080c192c94417b9625fa7a821cf49",
            "b83e85604d834e8cbd84f08b1b9236ea",
            "b73ce3b065de4ea98483201176c21ee9",
            "fade49683ba84a61b9fb78065168b03a",
            "b457246323e74221ad3e9b5854821c8f",
            "fc48bcfcfea144ee82c98f44315cf8b2",
            "a3d3bd4d897748b08b340551cfeae4c0",
            "c12c63660fcf4fe1916dc764f534fa46",
            "cd1f20330e584277a3fdce81e93970ef",
            "fd44b2584ff54279b0968ce32a317963",
            "e82659fd374d4a47afc0a2ad935d6a12",
            "030ada6ae78e44b0870239d22b8df0cc",
            "78683eb0b8074956827c43ac21efcede",
            "b59a870c8ded41748e3065a1644f2b56",
            "b466c34ead724eab9a306fc9d5260b0e",
            "1c34fc3f36314dea9c60beef9bda8403",
            "8f1608b9621f48438749b6e917fee70f",
            "7684eca0b17d40d4a50f0e788cdec043",
            "b5eaaf0f6d6f4f008ff82f79678d0480",
            "1bc6a9a33a6f4881b53c9e4d7b96370b",
            "32cd19c6d15a49bba41270df56173efd",
            "dd4a09c18f994ea3ac6265bd8dfefd71",
            "923993123a9d41aa857174cd0e644f47",
            "a24be8f5b36d4e8891f967f7e49ca218",
            "e5ed04f7e6ae462b9666b55ea6f627a0",
            "8fe61f75e9b74a828fadf3cbd0107bb3",
            "9faa281e74fc40bfb931591e0d59fa08",
            "5109563808bc456293c4b623f9e41079",
            "e26143bc9b5b420783db41200bba9773",
            "74ccca0b9391457b9e7e3dcdc0dfcd20",
            "e991886df9534f5d84350d1d7f51dc20",
            "d5f3de3036ee4a9f9b147ce29793056a",
            "3a0a7044d9cc497694916cd137ff5704",
            "f1c699e2c1d54394a2e6e9aebfa72c89",
            "5584d56889594d4c8d4c149dd427f435",
            "840fbeaf8e5642b6912a7806f21d51c9",
            "69c5e643ad1f49a2affa7a801e3142a6",
            "e9405c583d8e4bdcbafb82a66562fbfa",
            "8cd5624e229946c385513dd1d8d49a5e",
            "7ee21080d93a407292c07c0894c1ed7c",
            "a456e36367de467d9c11abd96919f2e6",
            "20f3e61be9ff4871bfe0e24af78c37b3",
            "848be9aa4635472eab988f3cd04087e5",
            "07cf11eb1a4c4f6c82c16dc2eaab794e",
            "0b5349227ae542f68d87eacaec8957aa",
            "5ab59a4894ce4d6790a39648a0c2a09f",
            "1b2cb290ad5248fba9b17c51f7815d14",
            "288dc8007ecc4ed7b30ebcc884082252",
            "88e60b1d0e8446fb9fdd837ebdde6897",
            "78969dd6bc0a4bbc9c5246f06abef13e",
            "17e5b6306950439a98746d31c54a5ca3",
            "b60ba8bd36fb4cb0a06d41b54a8676c5",
            "2b6d83c13291471cb9b0eae7eaff277e",
            "c2a58e7a7a454aa8b9688d93ebe6c32d",
            "4ddac5157dea4b13af266426990f9a13",
            "abe35d03e23f4376afa72b0261d0a403",
            "7912fa22f0434a2e83ec827917a3b629",
            "a25cd0fc2e624e12aaa995bef0b99e54",
            "debce2658964488e99c1cf3af7197126",
            "7a5d66ddec9245a5856013038ca9b83c",
            "69a9b40456764d328917b6230ada7977",
            "7aaa8e95aece4860ab33560c09bf11ab",
            "b38f4eaaf0794d4e8c9c165ad935cc78",
            "1baa241120b340b2b966eddb8b476794",
            "d2a2b0f1b5364b4cab14f6a159201cbe",
            "4cf6cf14e87548b1b21df8e2375164ec",
            "9a793c3cab7c440e8fe6463e3ac1672e",
            "f5d05393f8024064aca9a327ff284323",
            "d20394acaf89492bb65e9a77f6363c10",
            "33430c8a6cdc46008212f375b0224db1",
            "d0d5403d70d448c8af7d19a63e2b2fdb",
            "73dc7a3aefd9496cbfbac751ca17cbef",
            "07615e8e7eac4fceb0f33e3643ec69aa",
            "164e53fedd284ce08d7784fac5144e61",
            "0f9e3d4e88f348a8b1883f1921ff021e",
            "f6a487b3767c4e04af7eda580a2b9917",
            "064fd1f081274de9bbe0dee9c4bbc374",
            "eda2078993b24c6ca60d4b29844c78fa",
            "418fa5d70b96418189f0f156022bc2c9",
            "52c71b8421bb41789b382ee643e6ac37",
            "74ccf49c61214b61a14edcd384a2f61b",
            "4d36eba54d0c459eaba50913437f31d7",
            "f0d531ddb30d4a98b93aa8ebfb806afd",
            "90bc07c40aa140c0a1b747ed711d8bae",
            "e7ad0b5a58f447abb3c2225bbbfc7264",
            "2c20469819294bada3ebc661c2168ca3",
            "9de52af7c748469089796412947c0070",
            "68efcfe2bc934aab92fccca78291d9a8",
            "79ba8f3dac554d4787bb3c950cb90e5c",
            "d0d7d625faa140b4bebfbedc72d063c5",
            "6148215e5fde4c65ba89d19d7b699f53",
            "db28afa00d2441bb85e83c3b4ec60d30",
            "a9a02c86a898488abd3e5c78ca364d8d",
            "c1cd724ed5bb4fd9b2a882721e9d2ad4"
          ]
        },
        "id": "3bb313aa",
        "outputId": "6e2d441c-5c50-4f9e-c8f1-d082efa27e4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Training enhanced transformer with contextual representation...\n",
            "ðŸŽ¯ Enhanced training setup:\n",
            "   ðŸ“š Training examples: 65166\n",
            "   ðŸ”§ Learning rate: 5e-05\n",
            "   ðŸ“¦ Batch size: 24\n",
            "   âš–ï¸ Weighted loss function enabled\n",
            "\n",
            "ðŸš€ Starting enhanced contextual training...\n",
            "\n",
            "ðŸ“š Enhanced Epoch 1/10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Enhanced Training:   0%|          | 0/2716 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "970e63a3d94349e08cece97a4cc7ea92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ðŸ“Š Train: Loss 5.7704, Acc 0.197\n",
            "   ðŸ” Val: Loss 4.9844, Acc 0.213, BLEU 22.4\n",
            "   ðŸ“ˆ Type Accuracies: unknown: 0.213  \n",
            "      âœ… Best enhanced model saved! Acc: 0.213\n",
            "\n",
            "ðŸ“š Enhanced Epoch 2/10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Enhanced Training:   0%|          | 0/2716 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7c069c7066446a7917570721aa1df46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ðŸ“Š Train: Loss 3.4436, Acc 0.460\n",
            "   ðŸ” Val: Loss 3.3466, Acc 0.461, BLEU 31.7\n",
            "   ðŸ“ˆ Type Accuracies: unknown: 0.461  \n",
            "      âœ… Best enhanced model saved! Acc: 0.461\n",
            "\n",
            "ðŸ“š Enhanced Epoch 3/10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Enhanced Training:   0%|          | 0/2716 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3d3bd4d897748b08b340551cfeae4c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ðŸ“Š Train: Loss 1.8280, Acc 0.734\n",
            "   ðŸ” Val: Loss 1.8545, Acc 0.661, BLEU 63.2\n",
            "   ðŸ“ˆ Type Accuracies: unknown: 0.661  \n",
            "      âœ… Best enhanced model saved! Acc: 0.661\n",
            "\n",
            "ðŸ“š Enhanced Epoch 4/10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Enhanced Training:   0%|          | 0/2716 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7684eca0b17d40d4a50f0e788cdec043"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ðŸ“Š Train: Loss 0.8004, Acc 0.895\n",
            "   ðŸ” Val: Loss 1.0185, Acc 0.789, BLEU 89.3\n",
            "   ðŸ“ˆ Type Accuracies: unknown: 0.789  \n",
            "      âœ… Best enhanced model saved! Acc: 0.789\n",
            "\n",
            "ðŸ“š Enhanced Epoch 5/10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Enhanced Training:   0%|          | 0/2716 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e26143bc9b5b420783db41200bba9773"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ðŸ“Š Train: Loss 0.3280, Acc 0.956\n",
            "   ðŸ” Val: Loss 0.5920, Acc 0.860, BLEU 89.3\n",
            "   ðŸ“ˆ Type Accuracies: unknown: 0.860  \n",
            "      âœ… Best enhanced model saved! Acc: 0.860\n",
            "\n",
            "ðŸ“š Enhanced Epoch 6/10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Enhanced Training:   0%|          | 0/2716 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ee21080d93a407292c07c0894c1ed7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ðŸ“Š Train: Loss 0.1388, Acc 0.981\n",
            "   ðŸ” Val: Loss 0.3203, Acc 0.924, BLEU 100.0\n",
            "   ðŸ“ˆ Type Accuracies: unknown: 0.924  \n",
            "      âœ… Best enhanced model saved! Acc: 0.924\n",
            "\n",
            "ðŸ“š Enhanced Epoch 7/10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Enhanced Training:   0%|          | 0/2716 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17e5b6306950439a98746d31c54a5ca3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ðŸ“Š Train: Loss 0.0641, Acc 0.990\n",
            "   ðŸ” Val: Loss 0.2252, Acc 0.946, BLEU 100.0\n",
            "   ðŸ“ˆ Type Accuracies: unknown: 0.946  \n",
            "      âœ… Best enhanced model saved! Acc: 0.946\n",
            "\n",
            "ðŸ“š Enhanced Epoch 8/10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Enhanced Training:   0%|          | 0/2716 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7aaa8e95aece4860ab33560c09bf11ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ðŸ“Š Train: Loss 0.0360, Acc 0.994\n",
            "   ðŸ” Val: Loss 0.1859, Acc 0.955, BLEU 100.0\n",
            "   ðŸ“ˆ Type Accuracies: unknown: 0.955  \n",
            "      âœ… Best enhanced model saved! Acc: 0.955\n",
            "\n",
            "ðŸ“š Enhanced Epoch 9/10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Enhanced Training:   0%|          | 0/2716 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07615e8e7eac4fceb0f33e3643ec69aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ðŸ“Š Train: Loss 0.0245, Acc 0.995\n",
            "   ðŸ” Val: Loss 0.2044, Acc 0.957, BLEU 100.0\n",
            "   ðŸ“ˆ Type Accuracies: unknown: 0.957  \n",
            "      âœ… Best enhanced model saved! Acc: 0.957\n",
            "\n",
            "ðŸ“š Enhanced Epoch 10/10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Enhanced Training:   0%|          | 0/2716 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90bc07c40aa140c0a1b747ed711d8bae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ðŸ“Š Train: Loss 0.0180, Acc 0.996\n",
            "   ðŸ” Val: Loss 0.1553, Acc 0.965, BLEU 100.0\n",
            "   ðŸ“ˆ Type Accuracies: unknown: 0.965  \n",
            "      âœ… Best enhanced model saved! Acc: 0.965\n",
            "\n",
            "ðŸ† Enhanced training completed!\n",
            "   ðŸ“Š Best epoch: 10\n",
            "   ðŸŽ¯ Best accuracy: 0.965\n",
            "   ðŸ§  Used contextual representation with masking\n",
            "   ðŸ“ˆ Used probability-weighted training\n"
          ]
        }
      ],
      "source": [
        "# ðŸš€ ENHANCED TRANSFORMER TRAINING WITH CONTEXTUAL DATA\n",
        "print(\"ðŸš€ Training enhanced transformer with contextual representation...\")\n",
        "\n",
        "# Check dependencies from previous cells\n",
        "required_vars = ['enhanced_train_loader', 'enhanced_val_loader', 'enhanced_test_loader', 'VOCAB_SIZE', 'PAD_ID', 'BOS_ID', 'EOS_ID', 'UNK_ID', 'device', 'UrduTransformer', 'reconstruction_pairs', 'enhanced_contextual_pairs']\n",
        "missing_vars = [var for var in required_vars if var not in locals()]\n",
        "\n",
        "if missing_vars:\n",
        "    print(f\"âŒ Error: Missing required variables: {missing_vars}\")\n",
        "    print(\"Please run all previous cells in order.\")\n",
        "\n",
        "    # Try to check for alternative variable names\n",
        "    if 'enhanced_pairs' in locals():\n",
        "        print(\"ðŸ’¡ Found 'enhanced_pairs' - extracting required data...\")\n",
        "        reconstruction_pairs = [pair for pair in enhanced_pairs if pair['pair_type'] == 'reconstruction']\n",
        "        enhanced_contextual_pairs = [pair for pair in enhanced_pairs if pair['pair_type'] in ['enhanced_contextual', 'diverse_contextual', 'contextual_similarity']]\n",
        "        print(f\"âœ… Extracted: {len(reconstruction_pairs)} reconstruction pairs, {len(enhanced_contextual_pairs)} contextual pairs\")\n",
        "        missing_vars = [var for var in required_vars if var not in locals()]\n",
        "\n",
        "    if missing_vars:\n",
        "        print(f\"âŒ Still missing: {missing_vars}\")\n",
        "        print(\"Please ensure you've run the enhanced context representation cell first.\")\n",
        "else:\n",
        "    # Enhanced training functions with weighted loss\n",
        "    def enhanced_masked_loss(pred, target, mask, weights=None):\n",
        "        \"\"\"Enhanced loss function with optional weighting\"\"\"\n",
        "        pred_flat = pred.reshape(-1, VOCAB_SIZE)\n",
        "        target_flat = target.reshape(-1)\n",
        "        mask_flat = mask.reshape(-1)\n",
        "\n",
        "        if mask_flat.any():\n",
        "            loss = F.cross_entropy(pred_flat[mask_flat], target_flat[mask_flat], ignore_index=PAD_ID, reduction='none')\n",
        "\n",
        "            # Apply weights if provided\n",
        "            if weights is not None:\n",
        "                weights_expanded = weights.unsqueeze(1).expand(-1, target.size(1)).reshape(-1)\n",
        "                weights_masked = weights_expanded[mask_flat]\n",
        "                loss = (loss * weights_masked).mean()\n",
        "            else:\n",
        "                loss = loss.mean()\n",
        "            return loss\n",
        "        return torch.tensor(0.0, device=pred.device, requires_grad=True)\n",
        "\n",
        "    def enhanced_evaluate_model(model, loader, max_batches=None):\n",
        "        \"\"\"Enhanced evaluation with contextual metrics\"\"\"\n",
        "        model.eval()\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        total_tokens = 0\n",
        "        type_metrics = defaultdict(lambda: {'loss': 0, 'acc': 0, 'tokens': 0, 'count': 0})\n",
        "\n",
        "        predictions, targets = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(loader):\n",
        "                if max_batches and batch_idx >= max_batches:\n",
        "                    break\n",
        "\n",
        "                src = batch['src'].to(device)\n",
        "                tgt = batch['tgt'].to(device)\n",
        "                loss_mask = batch['loss_mask'].to(device)\n",
        "                weights = batch['weights'].to(device)\n",
        "                pair_types = batch['pair_types']\n",
        "\n",
        "                decoder_input = tgt[:, :-1]\n",
        "                decoder_target = tgt[:, 1:]\n",
        "                target_mask = loss_mask[:, 1:]\n",
        "\n",
        "                output = model(src, decoder_input)\n",
        "\n",
        "                # Calculate weighted loss\n",
        "                loss = enhanced_masked_loss(output, decoder_target, target_mask, weights)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                # Calculate accuracy\n",
        "                pred_tokens = torch.argmax(output, dim=-1)\n",
        "                mask_flat = target_mask.reshape(-1)\n",
        "\n",
        "                if mask_flat.any():\n",
        "                    correct = (pred_tokens.reshape(-1)[mask_flat] == decoder_target.reshape(-1)[mask_flat]).sum().item()\n",
        "                    tokens = mask_flat.sum().item()\n",
        "                    total_acc += correct\n",
        "                    total_tokens += tokens\n",
        "\n",
        "                    # Track metrics by pair type\n",
        "                    for i, pair_type in enumerate(pair_types):\n",
        "                        type_mask = target_mask[i].reshape(-1)\n",
        "                        if type_mask.any():\n",
        "                            type_correct = (pred_tokens[i].reshape(-1)[type_mask] == decoder_target[i].reshape(-1)[type_mask]).sum().item()\n",
        "                            type_tokens = type_mask.sum().item()\n",
        "                            type_metrics[pair_type]['acc'] += type_correct\n",
        "                            type_metrics[pair_type]['tokens'] += type_tokens\n",
        "                            type_metrics[pair_type]['count'] += 1\n",
        "\n",
        "                # Collect for BLEU (sample for efficiency)\n",
        "                if batch_idx < 10:  # Limit for efficiency\n",
        "                    for i in range(min(5, len(pred_tokens))):\n",
        "                        try:\n",
        "                            pred_clean = [t for t in pred_tokens[i].cpu().tolist() if t not in [PAD_ID, BOS_ID, EOS_ID, UNK_ID]]\n",
        "                            target_clean = [t for t in decoder_target[i].cpu().tolist() if t not in [PAD_ID, BOS_ID, EOS_ID, UNK_ID]]\n",
        "                            predictions.append(tokenizer.decode(pred_clean) if pred_clean else \"\")\n",
        "                            targets.append(tokenizer.decode(target_clean) if target_clean else \"\")\n",
        "                        except:\n",
        "                            continue\n",
        "\n",
        "        # Calculate final metrics\n",
        "        avg_loss = total_loss / len(loader) if len(loader) > 0 else 0\n",
        "        avg_acc = total_acc / total_tokens if total_tokens > 0 else 0\n",
        "\n",
        "        # BLEU score\n",
        "        try:\n",
        "            bleu = sacrebleu.corpus_bleu(predictions, [[t] for t in targets]).score if predictions else 0\n",
        "        except:\n",
        "            bleu = 0\n",
        "\n",
        "        # Type-specific accuracies\n",
        "        type_accs = {}\n",
        "        for pair_type, metrics in type_metrics.items():\n",
        "            if metrics['tokens'] > 0:\n",
        "                type_accs[pair_type] = metrics['acc'] / metrics['tokens']\n",
        "            else:\n",
        "                type_accs[pair_type] = 0\n",
        "\n",
        "        return {\n",
        "            'loss': avg_loss,\n",
        "            'accuracy': avg_acc,\n",
        "            'bleu': bleu,\n",
        "            'tokens': total_tokens,\n",
        "            'type_accuracies': type_accs\n",
        "        }\n",
        "\n",
        "    # Initialize enhanced model (same architecture, fresh weights for contextual training)\n",
        "    enhanced_model = UrduTransformer(\n",
        "        vocab_size=VOCAB_SIZE,\n",
        "        d_model=256,\n",
        "        heads=2,\n",
        "        num_encoder_layers=2,\n",
        "        num_decoder_layers=2,\n",
        "        d_ff=1024,\n",
        "        max_len=512,\n",
        "        dropout=0.1\n",
        "    ).to(device)\n",
        "\n",
        "    # Enhanced training setup\n",
        "    ENHANCED_LR = 5e-5  # Slightly lower learning rate for fine-tuned training\n",
        "    enhanced_optimizer = torch.optim.AdamW(enhanced_model.parameters(), lr=ENHANCED_LR, weight_decay=1e-4)\n",
        "    enhanced_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        enhanced_optimizer, mode='max', factor=0.7, patience=2\n",
        "    )\n",
        "\n",
        "    print(f\"ðŸŽ¯ Enhanced training setup:\")\n",
        "    print(f\"   ðŸ“š Training examples: {len(enhanced_train_loader.dataset) if enhanced_train_loader else 0}\")\n",
        "    print(f\"   ðŸ”§ Learning rate: {ENHANCED_LR}\")\n",
        "    print(f\"   ðŸ“¦ Batch size: 24\")\n",
        "    print(f\"   âš–ï¸ Weighted loss function enabled\")\n",
        "\n",
        "    # Enhanced training loop\n",
        "    NUM_ENHANCED_EPOCHS = 10\n",
        "    best_enhanced_acc = 0.0\n",
        "    best_enhanced_epoch = 0\n",
        "\n",
        "    enhanced_train_losses = []\n",
        "    enhanced_val_metrics = []\n",
        "\n",
        "    print(f\"\\nðŸš€ Starting enhanced contextual training...\")\n",
        "\n",
        "    for epoch in range(NUM_ENHANCED_EPOCHS):\n",
        "        print(f\"\\nðŸ“š Enhanced Epoch {epoch+1}/{NUM_ENHANCED_EPOCHS}\")\n",
        "\n",
        "        # Training phase\n",
        "        enhanced_model.train()\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        total_tokens = 0\n",
        "\n",
        "        train_progress = tqdm(enhanced_train_loader, desc=\"Enhanced Training\", leave=False)\n",
        "\n",
        "        for batch in train_progress:\n",
        "            src = batch['src'].to(device)\n",
        "            tgt = batch['tgt'].to(device)\n",
        "            loss_mask = batch['loss_mask'].to(device)\n",
        "            weights = batch['weights'].to(device)\n",
        "\n",
        "            decoder_input = tgt[:, :-1]\n",
        "            decoder_target = tgt[:, 1:]\n",
        "            target_mask = loss_mask[:, 1:]\n",
        "\n",
        "            enhanced_optimizer.zero_grad()\n",
        "\n",
        "            output = enhanced_model(src, decoder_input)\n",
        "            loss = enhanced_masked_loss(output, decoder_target, target_mask, weights)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(enhanced_model.parameters(), 1.0)\n",
        "            enhanced_optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            pred_tokens = torch.argmax(output, dim=-1)\n",
        "            mask_flat = target_mask.reshape(-1)\n",
        "            if mask_flat.any():\n",
        "                correct = (pred_tokens.reshape(-1)[mask_flat] == decoder_target.reshape(-1)[mask_flat]).sum().item()\n",
        "                tokens = mask_flat.sum().item()\n",
        "                total_acc += correct\n",
        "                total_tokens += tokens\n",
        "\n",
        "            train_progress.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'acc': f'{(total_acc/total_tokens)*100:.1f}%' if total_tokens > 0 else '0%'\n",
        "            })\n",
        "\n",
        "        avg_train_loss = total_loss / len(enhanced_train_loader)\n",
        "        avg_train_acc = total_acc / total_tokens if total_tokens > 0 else 0\n",
        "        enhanced_train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation phase\n",
        "        if enhanced_val_loader:\n",
        "            val_results = enhanced_evaluate_model(enhanced_model, enhanced_val_loader, max_batches=20)\n",
        "            enhanced_val_metrics.append(val_results)\n",
        "            enhanced_scheduler.step(val_results['accuracy'])\n",
        "\n",
        "            print(f\"   ðŸ“Š Train: Loss {avg_train_loss:.4f}, Acc {avg_train_acc:.3f}\")\n",
        "            print(f\"   ðŸ” Val: Loss {val_results['loss']:.4f}, Acc {val_results['accuracy']:.3f}, BLEU {val_results['bleu']:.1f}\")\n",
        "\n",
        "            # Print type-specific accuracies\n",
        "            if val_results['type_accuracies']:\n",
        "                print(f\"   ðŸ“ˆ Type Accuracies:\", end=\" \")\n",
        "                for pair_type, acc in val_results['type_accuracies'].items():\n",
        "                    print(f\"{pair_type}: {acc:.3f}\", end=\"  \")\n",
        "                print()\n",
        "\n",
        "            # Save best model\n",
        "            if val_results['accuracy'] > best_enhanced_acc:\n",
        "                best_enhanced_acc = val_results['accuracy']\n",
        "                best_enhanced_epoch = epoch\n",
        "\n",
        "                enhanced_checkpoint = {\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': enhanced_model.state_dict(),\n",
        "                    'optimizer_state_dict': enhanced_optimizer.state_dict(),\n",
        "                    'train_loss': avg_train_loss,\n",
        "                    'val_metrics': val_results,\n",
        "                    'best_accuracy': best_enhanced_acc,\n",
        "                    'enhanced_features': {\n",
        "                        'contextual_masking': True,\n",
        "                        'probability_weighting': True,\n",
        "                        'type_specific_loss': True,\n",
        "                        'reconstruction_pairs': len(reconstruction_pairs),\n",
        "                        'enhanced_contextual_pairs': len(enhanced_contextual_pairs)\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                torch.save(enhanced_checkpoint, '/content/urdu_files/best_enhanced_model.pth')\n",
        "                with open('/content/urdu_files/best_enhanced_model.pkl', 'wb') as f:\n",
        "                    pickle.dump(enhanced_checkpoint, f)\n",
        "\n",
        "                print(f\"      âœ… Best enhanced model saved! Acc: {val_results['accuracy']:.3f}\")\n",
        "        else:\n",
        "            print(f\"   ðŸ“Š Train: Loss {avg_train_loss:.4f}, Acc {avg_train_acc:.3f}\")\n",
        "            print(f\"   âš ï¸ No validation data available\")\n",
        "\n",
        "    print(f\"\\nðŸ† Enhanced training completed!\")\n",
        "    print(f\"   ðŸ“Š Best epoch: {best_enhanced_epoch + 1}\")\n",
        "    print(f\"   ðŸŽ¯ Best accuracy: {best_enhanced_acc:.3f}\")\n",
        "    print(f\"   ðŸ§  Used contextual representation with masking\")\n",
        "    print(f\"   ðŸ“ˆ Used probability-weighted training\")\n",
        "\n",
        "    # Save training history\n",
        "    enhanced_training_history = {\n",
        "        'train_losses': enhanced_train_losses,\n",
        "        'val_metrics': enhanced_val_metrics,\n",
        "        'best_epoch': best_enhanced_epoch,\n",
        "        'best_accuracy': best_enhanced_acc,\n",
        "        'num_epochs': NUM_ENHANCED_EPOCHS,\n",
        "        'learning_rate': ENHANCED_LR,\n",
        "        'batch_size': 24\n",
        "    }\n",
        "\n",
        "    with open('/content/urdu_files/enhanced_training_history.pkl', 'wb') as f:\n",
        "        pickle.dump(enhanced_training_history, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "16b95475",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16b95475",
        "outputId": "6e007119-bf26-44ed-a4fd-7d58f40bab02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ Testing final enhanced chatbot with contextual representation...\n",
            "âœ… Loaded best enhanced model\n",
            "\n",
            "ðŸ¤– Enhanced Chatbot Testing:\n",
            "============================================================\n",
            "\n",
            "1. ðŸ‘¤ Input: Ø³Ù„Ø§Ù… Ú©ÛŒØ§ Ø­Ø§Ù„ ÛÛ’ØŸ\n",
            "   ðŸ¤– Response: ÙˆØ§Ù‚ÙØ§Ù† ÛØ§Ø±Ø§ Ú©ÛŒØ§Øª Ø³Ú©ØªØ§ ÛÛŒØŸ\n",
            "\n",
            "2. ðŸ‘¤ Input: Ø¢Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚºØŸ\n",
            "   ðŸ¤– Response: Ø®ÙˆØ§Ø¨ÙˆÚº Ú©ÛŒ Ú†Ø§Ø¯Ø± Ø§ÙˆÚ‘Ú¾ÛŒ Ø­Ù‚ÛŒÙ‚ØªØ³ÙˆÛŒÚº\n",
            "\n",
            "3. ðŸ‘¤ Input: Ù…ÙˆØ³Ù… Ú©ÛŒØ³Ø§ ÛÛ’ØŸ\n",
            "   ðŸ¤– Response: ÛŒÛ ÛØ¶Ù… ÛÙˆØŸ\n",
            "\n",
            "4. ðŸ‘¤ Input: Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù… Ú©ÛŒØ§ ÛÛ’ØŸ\n",
            "   ðŸ¤– Response: ÙˆÛ Ø§ÙˆØª Ú©Ø§ Ù†Ø±Ø§ Ú©ÛŒØ§Û’ ØªÚ¾Ø¨Ø± Ú©Ø§ Ø¹Ø°Ø§Ø¨ Ú©ØªÙ†Ø§ Ø®Ø·Ø±Ù†Ø§Ú© ÛÛŒ\n",
            "\n",
            "5. ðŸ‘¤ Input: Ù…ÛŒÚº Ø®ÙˆØ´ ÛÙˆÚº\n",
            "   ðŸ¤– Response: Ø§Ù¾Ù†ÛŒ Ø§Ù¾ Ù…ÛŒÚº Ø¨ÛØª Ø®ÙˆØ´ ÛÙˆÚº\n",
            "\n",
            "6. ðŸ‘¤ Input: Ø´Ú©Ø±ÛŒÛ Ø¢Ù¾ Ú©Ø§\n",
            "   ðŸ¤– Response: Ù¾ÛŒÙ¾Ù„Ø²Ù¾Ø§Ø±Ù¹ÛŒ Ú©ÛŒ Ù¾Ø§Ø³ Ú©Ùˆ ÛŒÛŒ Ù…ØªØ¨Ø§Ø¯Ù„ ÛÛŒØŸ\n",
            "\n",
            "7. ðŸ‘¤ Input: Ø®Ø¯Ø§ Ø­Ø§ÙØ¸\n",
            "   ðŸ¤– Response: Ø¨Ø³Ú©Ù¹Ø±Ø§Ù†Ú© Ø¨Ù„Ù†Ø¯ ØªÚ¾ÛŒÛ”\n",
            "\n",
            "8. ðŸ‘¤ Input: Ø§Ø±Ø¯Ùˆ Ø²Ø¨Ø§Ù† Ú©Û’ Ø¨Ø§Ø±Û’ Ù…ÛŒÚº Ø¨ØªØ§Ø¦ÛŒÚº\n",
            "   ðŸ¤– Response: ÛØ± Ú©Ùˆ Ø§ÛŒÙ Ø§ÛŒ Ú©Ø§ Ø¯ÙˆØ³Ø±Ø§ Ø­Ø§Ù„ ÛÛŒ Ù…ØªØ±Ø§Ø¯Ù ÛÙˆÙ†Ø§\n",
            "\n",
            "ðŸ“Š Comprehensive Enhanced Model Evaluation:\n",
            "\n",
            "ðŸ† FINAL ENHANCED MODEL RESULTS:\n",
            "   ðŸŽ­ Accuracy: 0.959 (95.9%)\n",
            "   ðŸ“Š Loss: 0.1480\n",
            "   ðŸ“ˆ BLEU Score: 17.78\n",
            "   ðŸŽ¯ Perplexity: 1.16\n",
            "   ðŸ”¢ Tokens: 468\n",
            "\n",
            "ðŸ“ˆ Performance by Pair Type:\n",
            "   unknown: 0.959 (95.9%)\n",
            "\n",
            "ðŸ’¾ Final enhanced chatbot model saved:\n",
            "   ðŸ“¦ final_enhanced_chatbot_model.pkl\n",
            "   ðŸ“¦ final_enhanced_chatbot_model.pth\n",
            "\n",
            "âœ… ENHANCED CONTEXTUAL URDU CHATBOT COMPLETED!\n",
            "ðŸ§  Features implemented:\n",
            "   âœ… Context representation through masking\n",
            "   âœ… Probability-based sentence pairing\n",
            "   âœ… Multiple masking strategies\n",
            "   âœ… Reconstruction and similarity pairs\n",
            "   âœ… Weighted training for balanced learning\n",
            "   âœ… Enhanced transformer architecture\n",
            "   âœ… Comprehensive evaluation metrics\n",
            "\n",
            "ðŸ“Š FINAL PERFORMANCE SUMMARY:\n",
            "   ðŸŽ¯ Model Architecture: Custom Transformer Encoder-Decoder\n",
            "   ðŸ“š Training Data: 7,434 contextual pairs\n",
            "   ðŸŽ­ Final Accuracy: 0.959\n",
            "   ðŸ“ˆ BLEU Score: 17.78\n",
            "   ðŸ§  Context Method: Masking + Probability Distribution\n",
            "   âš–ï¸ Training Method: Weighted Loss with Type-specific Masking\n",
            "\n",
            "ðŸŽ‰ Enhanced Urdu Chatbot with Contextual Representation Ready!\n"
          ]
        }
      ],
      "source": [
        "# ðŸŽ¯ FINAL ENHANCED CHATBOT TESTING & GENERATION\n",
        "print(\"ðŸŽ¯ Testing final enhanced chatbot with contextual representation...\")\n",
        "\n",
        "# Check dependencies from previous cells\n",
        "required_vars = ['enhanced_model', 'enhanced_test_loader', 'tokenizer', 'device', 'BOS_ID', 'EOS_ID', 'PAD_ID', 'UNK_ID', 'enhanced_pairs', 'reconstruction_pairs', 'enhanced_contextual_pairs']\n",
        "missing_vars = [var for var in required_vars if var not in locals()]\n",
        "\n",
        "if missing_vars:\n",
        "    print(f\"âŒ Error: Missing required variables: {missing_vars}\")\n",
        "    print(\"Please run all previous cells in order.\")\n",
        "\n",
        "    # Try to check for alternative variable names and extract needed data\n",
        "    if 'enhanced_pairs' in locals():\n",
        "        print(\"ðŸ’¡ Found 'enhanced_pairs' - extracting required data...\")\n",
        "        try:\n",
        "            reconstruction_pairs = [pair for pair in enhanced_pairs if pair['pair_type'] == 'reconstruction']\n",
        "            enhanced_contextual_pairs = [pair for pair in enhanced_pairs if pair['pair_type'] in ['enhanced_contextual', 'diverse_contextual', 'contextual_similarity', 'similarity_based']]\n",
        "            print(f\"âœ… Extracted: {len(reconstruction_pairs)} reconstruction pairs, {len(enhanced_contextual_pairs)} contextual pairs\")\n",
        "            missing_vars = [var for var in required_vars if var not in locals()]\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Error extracting pairs: {e}\")\n",
        "\n",
        "    if missing_vars:\n",
        "        print(f\"âŒ Still missing: {missing_vars}\")\n",
        "        print(\"Please ensure you've run the enhanced training and context representation cells first.\")\n",
        "else:\n",
        "    # Load best enhanced model if it exists\n",
        "    try:\n",
        "        enhanced_model.load_state_dict(torch.load('/content/urdu_files/best_enhanced_model.pth')['model_state_dict'])\n",
        "        print(\"âœ… Loaded best enhanced model\")\n",
        "    except:\n",
        "        print(\"âš ï¸ Using current enhanced model (best model not found)\")\n",
        "\n",
        "    enhanced_model.eval()\n",
        "\n",
        "    def enhanced_generate_response(model, tokenizer, input_text, max_length=100, temperature=0.8):\n",
        "        \"\"\"Enhanced response generation with contextual understanding\"\"\"\n",
        "        model.eval()\n",
        "\n",
        "        # Tokenize input\n",
        "        input_ids = tokenizer.encode(input_text, add_bos=True, add_eos=False)\n",
        "        src_tensor = torch.tensor([input_ids], dtype=torch.long).to(device)\n",
        "\n",
        "        # Start with BOS token for decoder\n",
        "        generated = [BOS_ID]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for _ in range(max_length):\n",
        "                tgt_tensor = torch.tensor([generated], dtype=torch.long).to(device)\n",
        "\n",
        "                # Get model output\n",
        "                output = model(src_tensor, tgt_tensor)\n",
        "\n",
        "                # Apply temperature sampling\n",
        "                logits = output[0, -1, :] / temperature\n",
        "                probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "                # Sample next token\n",
        "                if temperature > 0:\n",
        "                    next_token = torch.multinomial(probs, num_samples=1).item()\n",
        "                else:\n",
        "                    next_token = torch.argmax(probs).item()\n",
        "\n",
        "                # Stop if EOS token\n",
        "                if next_token == EOS_ID:\n",
        "                    break\n",
        "\n",
        "                generated.append(next_token)\n",
        "\n",
        "        # Decode response (skip BOS token)\n",
        "        try:\n",
        "            response_ids = [t for t in generated[1:] if t not in [PAD_ID, UNK_ID]]\n",
        "            response = tokenizer.decode(response_ids)\n",
        "            return response.strip()\n",
        "        except:\n",
        "            return \"Ù…Ø¹Ø°Ø±ØªØŒ Ø¬ÙˆØ§Ø¨ ØªÛŒØ§Ø± Ù†ÛÛŒÚº ÛÙˆ Ø³Ú©Ø§Û”\"\n",
        "\n",
        "    # Test enhanced chatbot with various inputs\n",
        "    test_inputs = [\n",
        "        \"Ø³Ù„Ø§Ù… Ú©ÛŒØ§ Ø­Ø§Ù„ ÛÛ’ØŸ\",\n",
        "        \"Ø¢Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚºØŸ\",\n",
        "        \"Ù…ÙˆØ³Ù… Ú©ÛŒØ³Ø§ ÛÛ’ØŸ\",\n",
        "        \"Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù… Ú©ÛŒØ§ ÛÛ’ØŸ\",\n",
        "        \"Ù…ÛŒÚº Ø®ÙˆØ´ ÛÙˆÚº\",\n",
        "        \"Ø´Ú©Ø±ÛŒÛ Ø¢Ù¾ Ú©Ø§\",\n",
        "        \"Ø®Ø¯Ø§ Ø­Ø§ÙØ¸\",\n",
        "        \"Ø§Ø±Ø¯Ùˆ Ø²Ø¨Ø§Ù† Ú©Û’ Ø¨Ø§Ø±Û’ Ù…ÛŒÚº Ø¨ØªØ§Ø¦ÛŒÚº\"\n",
        "    ]\n",
        "\n",
        "    print(f\"\\nðŸ¤– Enhanced Chatbot Testing:\")\n",
        "    print(f\"=\" * 60)\n",
        "\n",
        "    enhanced_responses = []\n",
        "    for i, test_input in enumerate(test_inputs):\n",
        "        response = enhanced_generate_response(enhanced_model, tokenizer, test_input, max_length=50, temperature=0.7)\n",
        "        enhanced_responses.append({'input': test_input, 'response': response})\n",
        "\n",
        "        print(f\"\\n{i+1}. ðŸ‘¤ Input: {test_input}\")\n",
        "        print(f\"   ðŸ¤– Response: {response}\")\n",
        "\n",
        "    # Comprehensive testing on test dataset if available\n",
        "    if enhanced_test_loader and len(enhanced_test_loader) > 0:\n",
        "        print(f\"\\nðŸ“Š Comprehensive Enhanced Model Evaluation:\")\n",
        "        final_test_results = enhanced_evaluate_model(enhanced_model, enhanced_test_loader)\n",
        "\n",
        "        print(f\"\\nðŸ† FINAL ENHANCED MODEL RESULTS:\")\n",
        "        print(f\"   ðŸŽ­ Accuracy: {final_test_results['accuracy']:.3f} ({final_test_results['accuracy']*100:.1f}%)\")\n",
        "        print(f\"   ðŸ“Š Loss: {final_test_results['loss']:.4f}\")\n",
        "        print(f\"   ðŸ“ˆ BLEU Score: {final_test_results['bleu']:.2f}\")\n",
        "        print(f\"   ðŸŽ¯ Perplexity: {math.exp(final_test_results['loss']):.2f}\")\n",
        "        print(f\"   ðŸ”¢ Tokens: {final_test_results['tokens']:,}\")\n",
        "\n",
        "        # Type-specific performance\n",
        "        if final_test_results['type_accuracies']:\n",
        "            print(f\"\\nðŸ“ˆ Performance by Pair Type:\")\n",
        "            for pair_type, acc in final_test_results['type_accuracies'].items():\n",
        "                print(f\"   {pair_type}: {acc:.3f} ({acc*100:.1f}%)\")\n",
        "    else:\n",
        "        print(f\"\\nâš ï¸ No test data available for comprehensive evaluation\")\n",
        "        final_test_results = {\n",
        "            'accuracy': 0.0,\n",
        "            'loss': 0.0,\n",
        "            'bleu': 0.0,\n",
        "            'tokens': 0,\n",
        "            'type_accuracies': {}\n",
        "        }\n",
        "\n",
        "    # Save final results and model\n",
        "    final_model_package = {\n",
        "        'model_state_dict': enhanced_model.state_dict(),\n",
        "        'tokenizer_model': '/content/urdu_files/tokenizer.model',\n",
        "        'vocab_size': VOCAB_SIZE if 'VOCAB_SIZE' in locals() else 8000,\n",
        "        'model_config': {\n",
        "            'd_model': 256,\n",
        "            'heads': 2,\n",
        "            'encoder_layers': 2,\n",
        "            'decoder_layers': 2,\n",
        "            'max_len': 512,\n",
        "            'dropout': 0.1\n",
        "        },\n",
        "        'final_test_results': final_test_results,\n",
        "        'enhanced_features': {\n",
        "            'contextual_representation': True,\n",
        "            'masking_strategies': ['random', 'important_words', 'sequential'],\n",
        "            'probability_weighting': True,\n",
        "            'reconstruction_pairs': len(reconstruction_pairs) if 'reconstruction_pairs' in locals() else 0,\n",
        "            'enhanced_contextual_pairs': len(enhanced_contextual_pairs) if 'enhanced_contextual_pairs' in locals() else 0,\n",
        "            'total_training_pairs': len(enhanced_pairs) if 'enhanced_pairs' in locals() else 0\n",
        "        },\n",
        "        'test_responses': enhanced_responses\n",
        "    }\n",
        "\n",
        "    with open('/content/urdu_files/final_enhanced_chatbot_model.pkl', 'wb') as f:\n",
        "        pickle.dump(final_model_package, f)\n",
        "\n",
        "    torch.save(final_model_package, '/content/urdu_files/final_enhanced_chatbot_model.pth')\n",
        "\n",
        "    print(f\"\\nðŸ’¾ Final enhanced chatbot model saved:\")\n",
        "    print(f\"   ðŸ“¦ final_enhanced_chatbot_model.pkl\")\n",
        "    print(f\"   ðŸ“¦ final_enhanced_chatbot_model.pth\")\n",
        "\n",
        "    print(f\"\\nâœ… ENHANCED CONTEXTUAL URDU CHATBOT COMPLETED!\")\n",
        "    print(f\"ðŸ§  Features implemented:\")\n",
        "    print(f\"   âœ… Context representation through masking\")\n",
        "    print(f\"   âœ… Probability-based sentence pairing\")\n",
        "    print(f\"   âœ… Multiple masking strategies\")\n",
        "    print(f\"   âœ… Reconstruction and similarity pairs\")\n",
        "    print(f\"   âœ… Weighted training for balanced learning\")\n",
        "    print(f\"   âœ… Enhanced transformer architecture\")\n",
        "    print(f\"   âœ… Comprehensive evaluation metrics\")\n",
        "\n",
        "    # Performance comparison summary\n",
        "    print(f\"\\nðŸ“Š FINAL PERFORMANCE SUMMARY:\")\n",
        "    print(f\"   ðŸŽ¯ Model Architecture: Custom Transformer Encoder-Decoder\")\n",
        "    print(f\"   ðŸ“š Training Data: {len(enhanced_pairs) if 'enhanced_pairs' in locals() else 0:,} contextual pairs\")\n",
        "    print(f\"   ðŸŽ­ Final Accuracy: {final_test_results['accuracy']:.3f}\")\n",
        "    print(f\"   ðŸ“ˆ BLEU Score: {final_test_results['bleu']:.2f}\")\n",
        "    print(f\"   ðŸ§  Context Method: Masking + Probability Distribution\")\n",
        "    print(f\"   âš–ï¸ Training Method: Weighted Loss with Type-specific Masking\")\n",
        "\n",
        "    print(f\"\\nðŸŽ‰ Enhanced Urdu Chatbot with Contextual Representation Ready!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "970e63a3d94349e08cece97a4cc7ea92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_daa07920c0d74b1fb97f6451a432636d",
              "IPY_MODEL_a3bb3589507448d88e998009f134290a",
              "IPY_MODEL_0ac587b5deba483d9071657634a05fb3"
            ],
            "layout": "IPY_MODEL_0cd35ced22a84a05a0717dabd5fdf92d"
          }
        },
        "daa07920c0d74b1fb97f6451a432636d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fe4d71b58e1432cb52072c5705a5a38",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_137b8da439344526bc38008de8f9be13",
            "value": "Enhancedâ€‡Training:â€‡100%"
          }
        },
        "a3bb3589507448d88e998009f134290a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_448cb4eecdd54fa990940d57bd6aa052",
            "max": 2716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_faf3b1266afd45498cd8125261f01336",
            "value": 2716
          }
        },
        "0ac587b5deba483d9071657634a05fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7bacea7b3354360a976ccc9cea70976",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7ec6a05ce6aa42dc9c555374ce1f8b3d",
            "value": "â€‡2715/2716â€‡[01:18&lt;00:00,â€‡35.54it/s,â€‡loss=4.3287,â€‡acc=19.7%]"
          }
        },
        "0cd35ced22a84a05a0717dabd5fdf92d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "6fe4d71b58e1432cb52072c5705a5a38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "137b8da439344526bc38008de8f9be13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "448cb4eecdd54fa990940d57bd6aa052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf3b1266afd45498cd8125261f01336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7bacea7b3354360a976ccc9cea70976": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ec6a05ce6aa42dc9c555374ce1f8b3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7c069c7066446a7917570721aa1df46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8bdffb2b37c4600921ef4a4f27304d4",
              "IPY_MODEL_a67682dc3e79454d9c19bf576628cade",
              "IPY_MODEL_c5bd1f6e00064a62bbc87c617d45d82b"
            ],
            "layout": "IPY_MODEL_95008f9b46044d23ad7753367297e958"
          }
        },
        "d8bdffb2b37c4600921ef4a4f27304d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_412080c192c94417b9625fa7a821cf49",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b83e85604d834e8cbd84f08b1b9236ea",
            "value": "Enhancedâ€‡Training:â€‡100%"
          }
        },
        "a67682dc3e79454d9c19bf576628cade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b73ce3b065de4ea98483201176c21ee9",
            "max": 2716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fade49683ba84a61b9fb78065168b03a",
            "value": 2716
          }
        },
        "c5bd1f6e00064a62bbc87c617d45d82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b457246323e74221ad3e9b5854821c8f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fc48bcfcfea144ee82c98f44315cf8b2",
            "value": "â€‡2716/2716â€‡[01:15&lt;00:00,â€‡37.64it/s,â€‡loss=2.4941,â€‡acc=46.0%]"
          }
        },
        "95008f9b46044d23ad7753367297e958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "412080c192c94417b9625fa7a821cf49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b83e85604d834e8cbd84f08b1b9236ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b73ce3b065de4ea98483201176c21ee9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fade49683ba84a61b9fb78065168b03a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b457246323e74221ad3e9b5854821c8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc48bcfcfea144ee82c98f44315cf8b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3d3bd4d897748b08b340551cfeae4c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c12c63660fcf4fe1916dc764f534fa46",
              "IPY_MODEL_cd1f20330e584277a3fdce81e93970ef",
              "IPY_MODEL_fd44b2584ff54279b0968ce32a317963"
            ],
            "layout": "IPY_MODEL_e82659fd374d4a47afc0a2ad935d6a12"
          }
        },
        "c12c63660fcf4fe1916dc764f534fa46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_030ada6ae78e44b0870239d22b8df0cc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_78683eb0b8074956827c43ac21efcede",
            "value": "Enhancedâ€‡Training:â€‡100%"
          }
        },
        "cd1f20330e584277a3fdce81e93970ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b59a870c8ded41748e3065a1644f2b56",
            "max": 2716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b466c34ead724eab9a306fc9d5260b0e",
            "value": 2716
          }
        },
        "fd44b2584ff54279b0968ce32a317963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c34fc3f36314dea9c60beef9bda8403",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8f1608b9621f48438749b6e917fee70f",
            "value": "â€‡2715/2716â€‡[01:16&lt;00:00,â€‡38.26it/s,â€‡loss=1.2591,â€‡acc=73.4%]"
          }
        },
        "e82659fd374d4a47afc0a2ad935d6a12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "030ada6ae78e44b0870239d22b8df0cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78683eb0b8074956827c43ac21efcede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b59a870c8ded41748e3065a1644f2b56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b466c34ead724eab9a306fc9d5260b0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c34fc3f36314dea9c60beef9bda8403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f1608b9621f48438749b6e917fee70f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7684eca0b17d40d4a50f0e788cdec043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5eaaf0f6d6f4f008ff82f79678d0480",
              "IPY_MODEL_1bc6a9a33a6f4881b53c9e4d7b96370b",
              "IPY_MODEL_32cd19c6d15a49bba41270df56173efd"
            ],
            "layout": "IPY_MODEL_dd4a09c18f994ea3ac6265bd8dfefd71"
          }
        },
        "b5eaaf0f6d6f4f008ff82f79678d0480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_923993123a9d41aa857174cd0e644f47",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a24be8f5b36d4e8891f967f7e49ca218",
            "value": "Enhancedâ€‡Training:â€‡100%"
          }
        },
        "1bc6a9a33a6f4881b53c9e4d7b96370b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5ed04f7e6ae462b9666b55ea6f627a0",
            "max": 2716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fe61f75e9b74a828fadf3cbd0107bb3",
            "value": 2716
          }
        },
        "32cd19c6d15a49bba41270df56173efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9faa281e74fc40bfb931591e0d59fa08",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5109563808bc456293c4b623f9e41079",
            "value": "â€‡2716/2716â€‡[01:15&lt;00:00,â€‡37.45it/s,â€‡loss=0.3541,â€‡acc=89.5%]"
          }
        },
        "dd4a09c18f994ea3ac6265bd8dfefd71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "923993123a9d41aa857174cd0e644f47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a24be8f5b36d4e8891f967f7e49ca218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5ed04f7e6ae462b9666b55ea6f627a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fe61f75e9b74a828fadf3cbd0107bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9faa281e74fc40bfb931591e0d59fa08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5109563808bc456293c4b623f9e41079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e26143bc9b5b420783db41200bba9773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74ccca0b9391457b9e7e3dcdc0dfcd20",
              "IPY_MODEL_e991886df9534f5d84350d1d7f51dc20",
              "IPY_MODEL_d5f3de3036ee4a9f9b147ce29793056a"
            ],
            "layout": "IPY_MODEL_3a0a7044d9cc497694916cd137ff5704"
          }
        },
        "74ccca0b9391457b9e7e3dcdc0dfcd20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1c699e2c1d54394a2e6e9aebfa72c89",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5584d56889594d4c8d4c149dd427f435",
            "value": "Enhancedâ€‡Training:â€‡100%"
          }
        },
        "e991886df9534f5d84350d1d7f51dc20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_840fbeaf8e5642b6912a7806f21d51c9",
            "max": 2716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69c5e643ad1f49a2affa7a801e3142a6",
            "value": 2716
          }
        },
        "d5f3de3036ee4a9f9b147ce29793056a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9405c583d8e4bdcbafb82a66562fbfa",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8cd5624e229946c385513dd1d8d49a5e",
            "value": "â€‡2713/2716â€‡[01:15&lt;00:00,â€‡38.11it/s,â€‡loss=0.2113,â€‡acc=95.6%]"
          }
        },
        "3a0a7044d9cc497694916cd137ff5704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "f1c699e2c1d54394a2e6e9aebfa72c89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5584d56889594d4c8d4c149dd427f435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "840fbeaf8e5642b6912a7806f21d51c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69c5e643ad1f49a2affa7a801e3142a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9405c583d8e4bdcbafb82a66562fbfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cd5624e229946c385513dd1d8d49a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ee21080d93a407292c07c0894c1ed7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a456e36367de467d9c11abd96919f2e6",
              "IPY_MODEL_20f3e61be9ff4871bfe0e24af78c37b3",
              "IPY_MODEL_848be9aa4635472eab988f3cd04087e5"
            ],
            "layout": "IPY_MODEL_07cf11eb1a4c4f6c82c16dc2eaab794e"
          }
        },
        "a456e36367de467d9c11abd96919f2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b5349227ae542f68d87eacaec8957aa",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5ab59a4894ce4d6790a39648a0c2a09f",
            "value": "Enhancedâ€‡Training:â€‡100%"
          }
        },
        "20f3e61be9ff4871bfe0e24af78c37b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b2cb290ad5248fba9b17c51f7815d14",
            "max": 2716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_288dc8007ecc4ed7b30ebcc884082252",
            "value": 2716
          }
        },
        "848be9aa4635472eab988f3cd04087e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88e60b1d0e8446fb9fdd837ebdde6897",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_78969dd6bc0a4bbc9c5246f06abef13e",
            "value": "â€‡2714/2716â€‡[01:16&lt;00:00,â€‡35.66it/s,â€‡loss=0.1255,â€‡acc=98.1%]"
          }
        },
        "07cf11eb1a4c4f6c82c16dc2eaab794e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "0b5349227ae542f68d87eacaec8957aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ab59a4894ce4d6790a39648a0c2a09f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b2cb290ad5248fba9b17c51f7815d14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "288dc8007ecc4ed7b30ebcc884082252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88e60b1d0e8446fb9fdd837ebdde6897": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78969dd6bc0a4bbc9c5246f06abef13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17e5b6306950439a98746d31c54a5ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b60ba8bd36fb4cb0a06d41b54a8676c5",
              "IPY_MODEL_2b6d83c13291471cb9b0eae7eaff277e",
              "IPY_MODEL_c2a58e7a7a454aa8b9688d93ebe6c32d"
            ],
            "layout": "IPY_MODEL_4ddac5157dea4b13af266426990f9a13"
          }
        },
        "b60ba8bd36fb4cb0a06d41b54a8676c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abe35d03e23f4376afa72b0261d0a403",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7912fa22f0434a2e83ec827917a3b629",
            "value": "Enhancedâ€‡Training:â€‡100%"
          }
        },
        "2b6d83c13291471cb9b0eae7eaff277e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a25cd0fc2e624e12aaa995bef0b99e54",
            "max": 2716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_debce2658964488e99c1cf3af7197126",
            "value": 2716
          }
        },
        "c2a58e7a7a454aa8b9688d93ebe6c32d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a5d66ddec9245a5856013038ca9b83c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_69a9b40456764d328917b6230ada7977",
            "value": "â€‡2714/2716â€‡[01:15&lt;00:00,â€‡38.16it/s,â€‡loss=0.0210,â€‡acc=99.0%]"
          }
        },
        "4ddac5157dea4b13af266426990f9a13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "abe35d03e23f4376afa72b0261d0a403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7912fa22f0434a2e83ec827917a3b629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a25cd0fc2e624e12aaa995bef0b99e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "debce2658964488e99c1cf3af7197126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a5d66ddec9245a5856013038ca9b83c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69a9b40456764d328917b6230ada7977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7aaa8e95aece4860ab33560c09bf11ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b38f4eaaf0794d4e8c9c165ad935cc78",
              "IPY_MODEL_1baa241120b340b2b966eddb8b476794",
              "IPY_MODEL_d2a2b0f1b5364b4cab14f6a159201cbe"
            ],
            "layout": "IPY_MODEL_4cf6cf14e87548b1b21df8e2375164ec"
          }
        },
        "b38f4eaaf0794d4e8c9c165ad935cc78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a793c3cab7c440e8fe6463e3ac1672e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f5d05393f8024064aca9a327ff284323",
            "value": "Enhancedâ€‡Training:â€‡100%"
          }
        },
        "1baa241120b340b2b966eddb8b476794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d20394acaf89492bb65e9a77f6363c10",
            "max": 2716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33430c8a6cdc46008212f375b0224db1",
            "value": 2716
          }
        },
        "d2a2b0f1b5364b4cab14f6a159201cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0d5403d70d448c8af7d19a63e2b2fdb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_73dc7a3aefd9496cbfbac751ca17cbef",
            "value": "â€‡2716/2716â€‡[01:15&lt;00:00,â€‡36.83it/s,â€‡loss=0.0041,â€‡acc=99.4%]"
          }
        },
        "4cf6cf14e87548b1b21df8e2375164ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "9a793c3cab7c440e8fe6463e3ac1672e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5d05393f8024064aca9a327ff284323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d20394acaf89492bb65e9a77f6363c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33430c8a6cdc46008212f375b0224db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0d5403d70d448c8af7d19a63e2b2fdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73dc7a3aefd9496cbfbac751ca17cbef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07615e8e7eac4fceb0f33e3643ec69aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_164e53fedd284ce08d7784fac5144e61",
              "IPY_MODEL_0f9e3d4e88f348a8b1883f1921ff021e",
              "IPY_MODEL_f6a487b3767c4e04af7eda580a2b9917"
            ],
            "layout": "IPY_MODEL_064fd1f081274de9bbe0dee9c4bbc374"
          }
        },
        "164e53fedd284ce08d7784fac5144e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eda2078993b24c6ca60d4b29844c78fa",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_418fa5d70b96418189f0f156022bc2c9",
            "value": "Enhancedâ€‡Training:â€‡100%"
          }
        },
        "0f9e3d4e88f348a8b1883f1921ff021e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52c71b8421bb41789b382ee643e6ac37",
            "max": 2716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74ccf49c61214b61a14edcd384a2f61b",
            "value": 2716
          }
        },
        "f6a487b3767c4e04af7eda580a2b9917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d36eba54d0c459eaba50913437f31d7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f0d531ddb30d4a98b93aa8ebfb806afd",
            "value": "â€‡2716/2716â€‡[01:15&lt;00:00,â€‡37.09it/s,â€‡loss=0.0283,â€‡acc=99.5%]"
          }
        },
        "064fd1f081274de9bbe0dee9c4bbc374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "eda2078993b24c6ca60d4b29844c78fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "418fa5d70b96418189f0f156022bc2c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52c71b8421bb41789b382ee643e6ac37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74ccf49c61214b61a14edcd384a2f61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d36eba54d0c459eaba50913437f31d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0d531ddb30d4a98b93aa8ebfb806afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90bc07c40aa140c0a1b747ed711d8bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7ad0b5a58f447abb3c2225bbbfc7264",
              "IPY_MODEL_2c20469819294bada3ebc661c2168ca3",
              "IPY_MODEL_9de52af7c748469089796412947c0070"
            ],
            "layout": "IPY_MODEL_68efcfe2bc934aab92fccca78291d9a8"
          }
        },
        "e7ad0b5a58f447abb3c2225bbbfc7264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79ba8f3dac554d4787bb3c950cb90e5c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d0d7d625faa140b4bebfbedc72d063c5",
            "value": "Enhancedâ€‡Training:â€‡100%"
          }
        },
        "2c20469819294bada3ebc661c2168ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6148215e5fde4c65ba89d19d7b699f53",
            "max": 2716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db28afa00d2441bb85e83c3b4ec60d30",
            "value": 2716
          }
        },
        "9de52af7c748469089796412947c0070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9a02c86a898488abd3e5c78ca364d8d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c1cd724ed5bb4fd9b2a882721e9d2ad4",
            "value": "â€‡2715/2716â€‡[01:15&lt;00:00,â€‡39.25it/s,â€‡loss=0.0052,â€‡acc=99.6%]"
          }
        },
        "68efcfe2bc934aab92fccca78291d9a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "79ba8f3dac554d4787bb3c950cb90e5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0d7d625faa140b4bebfbedc72d063c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6148215e5fde4c65ba89d19d7b699f53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db28afa00d2441bb85e83c3b4ec60d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9a02c86a898488abd3e5c78ca364d8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1cd724ed5bb4fd9b2a882721e9d2ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}