# ğŸ¤– Urdu Conversational Chatbot - Ø§Ø±Ø¯Ùˆ Ú†ÛŒÙ¹ Ø¨ÙˆÙ¹

A sophisticated Urdu conversational chatbot built with Transformer architecture from scratch using PyTorch.

## ğŸš€ Features

- **Custom Transformer Architecture**: Built from scratch encoder-decoder model
- **Urdu Language Support**: Specialized tokenization and text processing for Urdu
- **Interactive UI**: Streamlit-based web interface with RTL text support
- **Multiple Decoding Strategies**: Greedy and beam search generation
- **Real-time Chat**: Responsive conversation interface

## ğŸ“‹ Requirements

```bash
torch>=1.9.0
streamlit>=1.25.0
sentencepiece>=0.1.97
numpy>=1.21.0
pandas>=1.3.0
```

## ğŸ› ï¸ Installation & Setup

### Method 1: Quick Setup (Recommended)

1. **Clone the repository**:
```bash
git clone https://github.com/hamxagithub/Urdu-Conversational-Chatbot-.git
cd Urdu-Conversational-Chatbot-
```

2. **Install dependencies**:
```bash
pip install torch streamlit sentencepiece numpy pandas
```

3. **Download model files** (if using Git LFS):
```bash
git lfs pull
```

4. **Run the chatbot**:
```bash
streamlit run app.py
```

### Method 2: Manual Model Download

If you encounter issues with large files:

1. Download model files manually from [Google Drive/OneDrive link]
2. Place them in the `files/` directory:
   - `best_model.pth` (92MB)
   - `best_model.pkl` (99MB)
   - `tokenizer.model`
   - `tokenizer.vocab`
   - `vocab_mapping.pkl`

## ğŸ“ Project Structure

```
Urdu_ChatBot/
â”œâ”€â”€ app.py                          # Main Streamlit application
â”œâ”€â”€ files/                          # Model and tokenizer files
â”‚   â”œâ”€â”€ best_model.pth              # Primary model weights (PyTorch)
â”‚   â”œâ”€â”€ best_model.pkl              # Fallback model weights (Pickle)
â”‚   â”œâ”€â”€ tokenizer.model             # SentencePiece model
â”‚   â”œâ”€â”€ tokenizer.vocab             # SentencePiece vocabulary
â”‚   â””â”€â”€ vocab_mapping.pkl           # Token-to-ID mapping
â”œâ”€â”€ check_model.py                  # Model validation script
â”œâ”€â”€ check_model_detailed.py         # Detailed model analysis
â””â”€â”€ *.ipynb                         # Training notebooks
```

## ğŸ¯ Usage

1. **Start the application**:
```bash
streamlit run app.py
```

2. **Access the web interface**:
   - Open your browser to `http://localhost:8501`
   - Type your message in Urdu
   - Select decoding strategy (Greedy/Beam Search)
   - Enjoy the conversation!

## ğŸ”§ Model Architecture

- **Encoder-Decoder Transformer**: Custom implementation
- **Vocabulary Size**: 8,000 tokens
- **Model Dimensions**: 256 (d_model)
- **Attention Heads**: 2
- **Encoder/Decoder Layers**: 2 each
- **Feed-Forward Dimension**: 1024
- **Max Sequence Length**: 512 tokens

## ğŸ“Š Performance

- **Training Dataset**: 20,000 Urdu conversation pairs
- **Vocabulary Coverage**: Comprehensive Urdu text normalization
- **Response Quality**: Natural conversational responses
- **Inference Speed**: ~0.1-0.8 seconds per response

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- Built for academic research in Urdu NLP
- Uses SentencePiece for efficient tokenization
- Streamlit for interactive web interface

## ğŸ“ Contact

For questions or issues, please open a GitHub issue or contact the maintainer.

---

**Made with â¤ï¸ for the Urdu language community**